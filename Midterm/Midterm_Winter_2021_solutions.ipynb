{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Midterm\n",
    "\n",
    "## Student ID: XXXXXXXXX (XX / 100)\n",
    "\n",
    "## General comments\n",
    "\n",
    "This Midterm integrates knowledge and skills acquired in the first half of the semester, especially in the first six Assignments. You are allowed to use any document and source on your computer and look up documents on the internet. **You are NOT allowed to share documents, or communicate in any other way with people inside or outside the class during the midterm.** To finish the midterm in the alloted 3 hrs, you will have to work efficiently. **Read the entirety of each question carefully.** You need to be signed into the Midterm Zoom session during the entire midterm with your video on and pointed at yourself. \n",
    "\n",
    "You need to submit the midterm by the due date (13:30) on OWL in the Test & Quizzes / Midterm section where you downloaded the data set and notebook. Late submission will be scored with 0 pts, unless you have received extra accommodation. To avoid technical difficulties, start your submission at latest five to ten minutes before the deadline. To be sure, you can also submit multiple version - only the latest version will be graded.  \n",
    "\n",
    "Most question demand a **written answer** - answer these in a full English sentence. \n",
    "\n",
    "For your Figures, ensure that all axes are labeled in an informative way. \n",
    "\n",
    "Ensure that your code runs correctly by choosing \"Kernel -> Restart and Run All\" before submitting. \n",
    "\n",
    "### Additional Guidance\n",
    "\n",
    "If at any point you are asking yourself \"are we supposed to...\", then *write your assumptions clearly in your exam and proceed according to those assumptions.*\n",
    "\n",
    "Good luck!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Preliminaries\n",
    "# Sets up the environment by importing \n",
    "# pandas, numpy, matplotlib, searborn, sklearn, scipy.\n",
    "# No other packages are allowed in solving the modterm.   \n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt \n",
    "%matplotlib inline\n",
    "import pandas as pd \n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import sklearn as sk \n",
    "import scipy \n",
    "\n",
    "# Get individual functions from \n",
    "from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import LinearRegression, Ridge, Lasso, LogisticRegression, LogisticRegressionCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import make_scorer, mean_absolute_error, r2_score, mean_squared_error\n",
    "from sklearn.metrics import confusion_matrix, roc_curve, precision_recall_curve, auc, plot_roc_curve\n",
    "from scipy.stats import norm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data set\n",
    "\n",
    "In 2007, Paulo Cortés and Aníbal Morais, at the University of Minho in Portugal, studied the use of data science techniques to tackle the challenging problem of forest fire prediction. They described their work as follows:\n",
    "\n",
    "\"Forest fires are a major environmental issue, creating economical andecological damage while endangering human lives. Fast detection is a key element for controlling such phenomenon. To achieve this, one alternative is to use automatic tools based on local sensors, such as provided by meteorological stations.\" \n",
    "\n",
    "In general, forest fire risks are measured using the Canadian Forest Fire Weather Index for rating forest fire danger (FFWI). You are provided with a dataset from the Montesinho natural park, from the Tras-os-Montes northeast region of Portugal. The data used in the experiments was collected from January 2000 to December 2003. At a daily basis, every time a forest fire occurred, several features were collected such as the time, date, spatial location within a 9×9 grid and the type of vegetation involved, four components of the FWI system and the total burned area, and complemented with several weather observations (e.g. wind speed) recorded at the time of the event. The specific variables available to you are:\n",
    "\n",
    "1. X - x-axis spatial coordinate within the Montesinho park map: 1 to 9\n",
    "2. Y - y-axis spatial coordinate within the Montesinho park map: 2 to 9\n",
    "3. month - month of the year: 1 to 12 (categorical)\n",
    "4. day - day of the week: 1 to 7 (categorical)\n",
    "5. FFMC - FFMC (Rain, Temperature, Wind and Humidity relationship) index from the FWI system: 18.7 to 96.20\n",
    "6. DMC - DMC (Rain, Temperature,and Humidity relationship) index from the FWI system: 1.1 to 291.3\n",
    "7. DC - DC (Rain and Temperature relationship) index from the FWI system: 7.9 to 860.6\n",
    "8. ISI - ISI (Wind speed risk) index from the FWI system: 0.0 to 56.10\n",
    "9. temp - temperature in Celsius degrees: 2.2 to 33.30\n",
    "10. RH - relative humidity in %: 15.0 to 100\n",
    "11. wind - wind speed in km/h: 0.40 to 9.40\n",
    "12. rain - outside rain in mm/m2 : 0.0 to 6.4\n",
    "13. area - the burned area of the forest (in ha): 0.00 to 1090.84 (**target variable**).\n",
    "\n",
    "With this information, answer the following questions using your knowledge from the course.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 1: Predicting the size of the burned area (30 pts)\n",
    "\n",
    "### Question 1.1: Data loading (X / 4 pts)\n",
    "\n",
    "Load the data and present the basic descriptive statistics for all variables. How many cases are there? Are there any null values?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>X</th>\n",
       "      <th>Y</th>\n",
       "      <th>month</th>\n",
       "      <th>day</th>\n",
       "      <th>FFMC</th>\n",
       "      <th>DMC</th>\n",
       "      <th>DC</th>\n",
       "      <th>ISI</th>\n",
       "      <th>temp</th>\n",
       "      <th>RH</th>\n",
       "      <th>wind</th>\n",
       "      <th>rain</th>\n",
       "      <th>area</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>517.000000</td>\n",
       "      <td>517.000000</td>\n",
       "      <td>517.000000</td>\n",
       "      <td>517.000000</td>\n",
       "      <td>517.000000</td>\n",
       "      <td>517.000000</td>\n",
       "      <td>517.000000</td>\n",
       "      <td>517.000000</td>\n",
       "      <td>517.000000</td>\n",
       "      <td>517.000000</td>\n",
       "      <td>517.000000</td>\n",
       "      <td>517.000000</td>\n",
       "      <td>517.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>4.669246</td>\n",
       "      <td>4.299807</td>\n",
       "      <td>7.475822</td>\n",
       "      <td>4.259188</td>\n",
       "      <td>90.644681</td>\n",
       "      <td>110.872340</td>\n",
       "      <td>547.940039</td>\n",
       "      <td>9.021663</td>\n",
       "      <td>18.889168</td>\n",
       "      <td>44.288201</td>\n",
       "      <td>4.017602</td>\n",
       "      <td>0.021663</td>\n",
       "      <td>12.847292</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>2.313778</td>\n",
       "      <td>1.229900</td>\n",
       "      <td>2.275990</td>\n",
       "      <td>2.072929</td>\n",
       "      <td>5.520111</td>\n",
       "      <td>64.046482</td>\n",
       "      <td>248.066192</td>\n",
       "      <td>4.559477</td>\n",
       "      <td>5.806625</td>\n",
       "      <td>16.317469</td>\n",
       "      <td>1.791653</td>\n",
       "      <td>0.295959</td>\n",
       "      <td>63.655818</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>18.700000</td>\n",
       "      <td>1.100000</td>\n",
       "      <td>7.900000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.200000</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>3.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>90.200000</td>\n",
       "      <td>68.600000</td>\n",
       "      <td>437.700000</td>\n",
       "      <td>6.500000</td>\n",
       "      <td>15.500000</td>\n",
       "      <td>33.000000</td>\n",
       "      <td>2.700000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>91.600000</td>\n",
       "      <td>108.300000</td>\n",
       "      <td>664.200000</td>\n",
       "      <td>8.400000</td>\n",
       "      <td>19.300000</td>\n",
       "      <td>42.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.520000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>7.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>92.900000</td>\n",
       "      <td>142.400000</td>\n",
       "      <td>713.900000</td>\n",
       "      <td>10.800000</td>\n",
       "      <td>22.800000</td>\n",
       "      <td>53.000000</td>\n",
       "      <td>4.900000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>6.570000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>9.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>96.200000</td>\n",
       "      <td>291.300000</td>\n",
       "      <td>860.600000</td>\n",
       "      <td>56.100000</td>\n",
       "      <td>33.300000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>9.400000</td>\n",
       "      <td>6.400000</td>\n",
       "      <td>1090.840000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                X           Y       month         day        FFMC         DMC  \\\n",
       "count  517.000000  517.000000  517.000000  517.000000  517.000000  517.000000   \n",
       "mean     4.669246    4.299807    7.475822    4.259188   90.644681  110.872340   \n",
       "std      2.313778    1.229900    2.275990    2.072929    5.520111   64.046482   \n",
       "min      1.000000    2.000000    1.000000    1.000000   18.700000    1.100000   \n",
       "25%      3.000000    4.000000    7.000000    2.000000   90.200000   68.600000   \n",
       "50%      4.000000    4.000000    8.000000    5.000000   91.600000  108.300000   \n",
       "75%      7.000000    5.000000    9.000000    6.000000   92.900000  142.400000   \n",
       "max      9.000000    9.000000   12.000000    7.000000   96.200000  291.300000   \n",
       "\n",
       "               DC         ISI        temp          RH        wind        rain  \\\n",
       "count  517.000000  517.000000  517.000000  517.000000  517.000000  517.000000   \n",
       "mean   547.940039    9.021663   18.889168   44.288201    4.017602    0.021663   \n",
       "std    248.066192    4.559477    5.806625   16.317469    1.791653    0.295959   \n",
       "min      7.900000    0.000000    2.200000   15.000000    0.400000    0.000000   \n",
       "25%    437.700000    6.500000   15.500000   33.000000    2.700000    0.000000   \n",
       "50%    664.200000    8.400000   19.300000   42.000000    4.000000    0.000000   \n",
       "75%    713.900000   10.800000   22.800000   53.000000    4.900000    0.000000   \n",
       "max    860.600000   56.100000   33.300000  100.000000    9.400000    6.400000   \n",
       "\n",
       "              area  \n",
       "count   517.000000  \n",
       "mean     12.847292  \n",
       "std      63.655818  \n",
       "min       0.000000  \n",
       "25%       0.000000  \n",
       "50%       0.520000  \n",
       "75%       6.570000  \n",
       "max    1090.840000  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "FF = pd.read_csv('forestfires.csv')\n",
    "FF.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Written answer: There are 517 observations. No variables have null values.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 1.2: Data cleaning (X / 3 pts)\n",
    "\n",
    "The variables 'month' and 'day' are numerical. Transform these two so they are dummmy coded. Because in this question we are using non-regularized models, drop the first column for each variable. Written answer: How many new variables you created?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>X</th>\n",
       "      <th>Y</th>\n",
       "      <th>FFMC</th>\n",
       "      <th>DMC</th>\n",
       "      <th>DC</th>\n",
       "      <th>ISI</th>\n",
       "      <th>temp</th>\n",
       "      <th>RH</th>\n",
       "      <th>wind</th>\n",
       "      <th>rain</th>\n",
       "      <th>...</th>\n",
       "      <th>month_9</th>\n",
       "      <th>month_10</th>\n",
       "      <th>month_11</th>\n",
       "      <th>month_12</th>\n",
       "      <th>day_2</th>\n",
       "      <th>day_3</th>\n",
       "      <th>day_4</th>\n",
       "      <th>day_5</th>\n",
       "      <th>day_6</th>\n",
       "      <th>day_7</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>517.000000</td>\n",
       "      <td>517.000000</td>\n",
       "      <td>517.000000</td>\n",
       "      <td>517.000000</td>\n",
       "      <td>517.000000</td>\n",
       "      <td>517.000000</td>\n",
       "      <td>517.000000</td>\n",
       "      <td>517.000000</td>\n",
       "      <td>517.000000</td>\n",
       "      <td>517.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>517.000000</td>\n",
       "      <td>517.000000</td>\n",
       "      <td>517.000000</td>\n",
       "      <td>517.000000</td>\n",
       "      <td>517.000000</td>\n",
       "      <td>517.000000</td>\n",
       "      <td>517.000000</td>\n",
       "      <td>517.000000</td>\n",
       "      <td>517.000000</td>\n",
       "      <td>517.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>4.669246</td>\n",
       "      <td>4.299807</td>\n",
       "      <td>90.644681</td>\n",
       "      <td>110.872340</td>\n",
       "      <td>547.940039</td>\n",
       "      <td>9.021663</td>\n",
       "      <td>18.889168</td>\n",
       "      <td>44.288201</td>\n",
       "      <td>4.017602</td>\n",
       "      <td>0.021663</td>\n",
       "      <td>...</td>\n",
       "      <td>0.332689</td>\n",
       "      <td>0.029014</td>\n",
       "      <td>0.001934</td>\n",
       "      <td>0.017408</td>\n",
       "      <td>0.123791</td>\n",
       "      <td>0.104449</td>\n",
       "      <td>0.117988</td>\n",
       "      <td>0.164410</td>\n",
       "      <td>0.162476</td>\n",
       "      <td>0.183752</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>2.313778</td>\n",
       "      <td>1.229900</td>\n",
       "      <td>5.520111</td>\n",
       "      <td>64.046482</td>\n",
       "      <td>248.066192</td>\n",
       "      <td>4.559477</td>\n",
       "      <td>5.806625</td>\n",
       "      <td>16.317469</td>\n",
       "      <td>1.791653</td>\n",
       "      <td>0.295959</td>\n",
       "      <td>...</td>\n",
       "      <td>0.471632</td>\n",
       "      <td>0.168007</td>\n",
       "      <td>0.043980</td>\n",
       "      <td>0.130913</td>\n",
       "      <td>0.329662</td>\n",
       "      <td>0.306138</td>\n",
       "      <td>0.322907</td>\n",
       "      <td>0.371006</td>\n",
       "      <td>0.369244</td>\n",
       "      <td>0.387657</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>18.700000</td>\n",
       "      <td>1.100000</td>\n",
       "      <td>7.900000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.200000</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>3.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>90.200000</td>\n",
       "      <td>68.600000</td>\n",
       "      <td>437.700000</td>\n",
       "      <td>6.500000</td>\n",
       "      <td>15.500000</td>\n",
       "      <td>33.000000</td>\n",
       "      <td>2.700000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>91.600000</td>\n",
       "      <td>108.300000</td>\n",
       "      <td>664.200000</td>\n",
       "      <td>8.400000</td>\n",
       "      <td>19.300000</td>\n",
       "      <td>42.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>7.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>92.900000</td>\n",
       "      <td>142.400000</td>\n",
       "      <td>713.900000</td>\n",
       "      <td>10.800000</td>\n",
       "      <td>22.800000</td>\n",
       "      <td>53.000000</td>\n",
       "      <td>4.900000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>9.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>96.200000</td>\n",
       "      <td>291.300000</td>\n",
       "      <td>860.600000</td>\n",
       "      <td>56.100000</td>\n",
       "      <td>33.300000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>9.400000</td>\n",
       "      <td>6.400000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 28 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                X           Y        FFMC         DMC          DC         ISI  \\\n",
       "count  517.000000  517.000000  517.000000  517.000000  517.000000  517.000000   \n",
       "mean     4.669246    4.299807   90.644681  110.872340  547.940039    9.021663   \n",
       "std      2.313778    1.229900    5.520111   64.046482  248.066192    4.559477   \n",
       "min      1.000000    2.000000   18.700000    1.100000    7.900000    0.000000   \n",
       "25%      3.000000    4.000000   90.200000   68.600000  437.700000    6.500000   \n",
       "50%      4.000000    4.000000   91.600000  108.300000  664.200000    8.400000   \n",
       "75%      7.000000    5.000000   92.900000  142.400000  713.900000   10.800000   \n",
       "max      9.000000    9.000000   96.200000  291.300000  860.600000   56.100000   \n",
       "\n",
       "             temp          RH        wind        rain  ...     month_9  \\\n",
       "count  517.000000  517.000000  517.000000  517.000000  ...  517.000000   \n",
       "mean    18.889168   44.288201    4.017602    0.021663  ...    0.332689   \n",
       "std      5.806625   16.317469    1.791653    0.295959  ...    0.471632   \n",
       "min      2.200000   15.000000    0.400000    0.000000  ...    0.000000   \n",
       "25%     15.500000   33.000000    2.700000    0.000000  ...    0.000000   \n",
       "50%     19.300000   42.000000    4.000000    0.000000  ...    0.000000   \n",
       "75%     22.800000   53.000000    4.900000    0.000000  ...    1.000000   \n",
       "max     33.300000  100.000000    9.400000    6.400000  ...    1.000000   \n",
       "\n",
       "         month_10    month_11    month_12       day_2       day_3       day_4  \\\n",
       "count  517.000000  517.000000  517.000000  517.000000  517.000000  517.000000   \n",
       "mean     0.029014    0.001934    0.017408    0.123791    0.104449    0.117988   \n",
       "std      0.168007    0.043980    0.130913    0.329662    0.306138    0.322907   \n",
       "min      0.000000    0.000000    0.000000    0.000000    0.000000    0.000000   \n",
       "25%      0.000000    0.000000    0.000000    0.000000    0.000000    0.000000   \n",
       "50%      0.000000    0.000000    0.000000    0.000000    0.000000    0.000000   \n",
       "75%      0.000000    0.000000    0.000000    0.000000    0.000000    0.000000   \n",
       "max      1.000000    1.000000    1.000000    1.000000    1.000000    1.000000   \n",
       "\n",
       "            day_5       day_6       day_7  \n",
       "count  517.000000  517.000000  517.000000  \n",
       "mean     0.164410    0.162476    0.183752  \n",
       "std      0.371006    0.369244    0.387657  \n",
       "min      0.000000    0.000000    0.000000  \n",
       "25%      0.000000    0.000000    0.000000  \n",
       "50%      0.000000    0.000000    0.000000  \n",
       "75%      0.000000    0.000000    0.000000  \n",
       "max      1.000000    1.000000    1.000000  \n",
       "\n",
       "[8 rows x 28 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "FF = pd.get_dummies(FF, drop_first=True, columns=['month','day'])\n",
    "FF.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Written answer: There are (7 - 1) + (12 - 1) = 17 new variables created.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 1.3: Data visualization (X / 5 pts)\n",
    "\n",
    "Create a joint plot of the distribution between the temperature and the area. In the same plot, show the marginal distributions of these two variables seperately. Written answer: How would you characterize the distribution of `Area`? Is there a relationship between temperature and area? If yes, how would you describe it? \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAbIAAAGoCAYAAAAjPmDhAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjEsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy8QZhcZAAAgAElEQVR4nO3df5RkdXnn8fczPT3aTBIbdDDSQMCEBRMxDJkACTk5AllBTcKskaDGhLhk2T0xuxFzZgNZN4IxK1myMeZsosEfCW7UQBRHjK5IEJPoWdHBGRgROBKDMD0oo0OjQiPNzLN/1K2Zmp6q6qqe+vWtfr/O6TNVt25VP1XTdT/1fe733orMRJKkUq0adgGSJB0Kg0ySVDSDTJJUNINMklQ0g0ySVLTVwy6gT5yKKWncxLALGFWOyCRJRTPIJElFG9fWolSE99/2wLLv+6rTj+1hJVK5HJFJkopmkEmSimZrUToEh9IalNQbjsgkSUUzyCRJRTPIJElFM8gkSUUzyCRJRTPIJElFM8gkSUXzODKtaB4HJpXPIJMKdagh7LkaNS5sLUqSiuaITFqhHNFpXDgikyQVzSCTJBXNIJMkFc0gkyQVzSCTJBXNIJMkFc3p9yqeZ+eQVjZHZJKkohlkkqSiGWSSpKIZZJKkohlkkqSiGWSSpKIZZJKkohlkkqSiGWSSpKIZZJKkonmKKg2dp5iSdCgMMvWEYSRpWAwySQN3qB98XnX6sT2qROPAIJO0LI7CNSqc7CFJKppBJkkqmkEmSSqa+8h6yB3YkjR4jsgkSUUzyCRJRbO1KMCp1JLKZZCNCYNI0kplkEkqzqF8cHNS1fhxH5kkqWgGmSSpaLYWJa0ow96fbGuz9xyRSZKK5ohshAz7k6IklcgRmSSpaI7IGjgikqTyRGYOu4aei4hPAM8adh1tPAv45rCL6JI1D0aJNUOZdZdW8zcz87xhFzGKxjLIRl1EbMnMDcOuoxvWPBgl1gxl1l1izWrOfWSSpKIZZJKkohlkw3HNsAtYBmsejBJrhjLrLrFmNeE+MklS0RyRSZKKZpBJkopmkEmSimaQSZKKNpZBdt555yXgjz/++DNOPx0Z4+1fS2MZZN/8ZklnnZGk3lmJ27+xDDJJ0sphkEmSimaQSZKKZpBJkopmkEmSimaQSZKKZpBJkopmkEmSimaQSZKKZpBJkoq2etgFSCrb5q2zXH3Tveycm+eo6Sk2nXsiG9fPDLssrSAGmaRl27x1lstv2M78wh4AZufmufyG7QCGmQbG1qKkZbv6pnv3hVjd/MIerr7p3iFVpJXIIJO0bDvn5rtarv7b/diTwy5h4AwySct21PRUV8ulfjDIJC3bpnNPZGpy4oBlU5MTbDr3xCFVpJXIyR6Slq0+ocNZixomg0zSIdm4fsbg0lDZWpSkMXLE2jXDLmHgDDJJUtEMMklS0QwySVLRDDJJUtEMMklS0QwySVLRDDJJUtEMMklS0QwySVLRDDJJUtEMMklS0QwySVLRDDJJUtEMMklS0foWZBHxnoh4OCK+1LDsiIi4OSK+Uv17eLU8IuLPIuK+iLgzIk5tuM9F1fpfiYiL+lWvJKlM/RyR/TVw3qJllwG3ZOYJwC3VdYAXAydUP5cAb4da8AFvBE4HTgPeWA8/SZKgj0GWmf8E7F60+Hzg2urytcDGhuXvzZrPAdMR8RzgXODmzNydmY8AN3NwOEqSVrBB7yN7dmY+BFD9e2S1fAZ4sGG9HdWyVsslSQJGZ7JHNFmWbZYf/AARl0TElojYsmvXrp4WJ0mjbKVv/wYdZN+oWoZU/z5cLd8BHNOw3tHAzjbLD5KZ12TmhszcsG7dup4XLkmjaqVv/wYdZDcC9ZmHFwEfaVj+a9XsxTOAR6vW403AiyLi8GqSx4uqZZIkAbC6Xw8cER8AXgg8KyJ2UJt9eBVwfURcDDwAXFCt/nHgJcB9wOPAawAyc3dE/AHwhWq9N2Xm4gkkkqQVrG9BlpmvbHHTOU3WTeC1LR7nPcB7eliaJGmMjMpkD0mSlsUgkyQVzSCTJBXNIJMkFc0gkyQVzSCTJBXNIJMkFc0gkyQVzSCTJBXNIJMkFc0gkyQVzSCTJBXNIJMkFc0gkyQVzSCTJBXNIJMkFc0gkyQVzSCTJBXNIJMkFc0gkyQVzSCTJBXNIJMkFc0gkyQVzSCTJBXNIJMkFc0gkyQVzSCTJBXNIJMkFc0gkyQVzSCTJBXNIJMkFc0gkyQVzSCTJBXNIJMkFc0gkyQVzSCTJBXNIJMkFc0gkyQVzSCTJBXNIJMkFc0gkyQVzSCTJBXNIJMkFc0gkyQVbShBFhGXRsRdEfGliPhARDw9Io6PiNsi4isRcV1ErKnWfVp1/b7q9uOGUbMkaTQNPMgiYgb4L8CGzHw+MAG8Avgj4K2ZeQLwCHBxdZeLgUcy80eAt1brSZIEDK+1uBqYiojVwGHAQ8DZwAer268FNlaXz6+uU91+TkTEAGuVJI2wgQdZZs4Cfww8QC3AHgVuB+Yy86lqtR3ATHV5Bniwuu9T1frPXPy4EXFJRGyJiC27du3q75OQpBGy0rd/w2gtHk5tlHU8cBSwFnhxk1Wzfpc2t+1fkHlNZm7IzA3r1q3rVbmSNPJW+vZvGK3FnwP+NTN3ZeYCcAPw08B01WoEOBrYWV3eARwDUN3+DGD3YEuWJI2qYQTZA8AZEXFYta/rHODLwK3Ay6t1LgI+Ul2+sbpOdfunMvOgEZkkaWUaxj6y26hN2vgisL2q4Rrgd4HXR8R91PaBvbu6y7uBZ1bLXw9cNuiaJUmja/XSq/ReZr4ReOOixV8FTmuy7hPABYOoS5JUHs/sIUkqmkEmSSqaQSZJKppBJkljZPdjTw67hIEzyCRJRRvKrEVJamfz1lmuvuleds7Nc9T0FJvOPZGN62eWvqNWJINM0kjZvHWWy2/YzvzCHgBm5+a5/IbtAIaZmrK1KGmkXH3TvftCrG5+YQ9X33TvkCrSqDPIJI2UnXPzXS2XDDJJI+Wo6amulutAR6xdM+wSBs4gkzRSNp17IlOTEwcsm5qcYNO5Jw6pIo06J3tIGin1CR3OWlSnDDJJI2fj+hmDSx2ztShJKppBJkkqmkEmSSqaQSZJKppBJkkqmkEmSSqaQSZJKppBJkkqmkEmSSqaQSZJKppBJkkqmkEmSSqaQSZJKppBJkkqmkEmSSqaQSZJKppBJkkqmkEmSSqaQSZJKppBJkkqmkEmSSqaQSZJKppBJkkqmkEmSSqaQSZJKppBJkkqmkEmSSqaQSZJKppBJkkqmkEmSSraUIIsIqYj4oMRcU9E3B0RPxURR0TEzRHxlerfw6t1IyL+LCLui4g7I+LUYdQsSRpNwxqRvQ34RGaeBPw4cDdwGXBLZp4A3FJdB3gxcEL1cwnw9sGXK0kaVQMPsoj4AeBngXcDZOaTmTkHnA9cW612LbCxunw+8N6s+RwwHRHPGXDZkqQRNYwR2XOBXcBfRcTWiHhXRKwFnp2ZDwFU/x5ZrT8DPNhw/x3VsgNExCURsSUituzatau/z0CSRshK3/4NI8hWA6cCb8/M9cBj7G8jNhNNluVBCzKvycwNmblh3bp1valUkgqw0rd/wwiyHcCOzLytuv5BasH2jXrLsPr34Yb1j2m4/9HAzgHVKkkacQMPssz8OvBgRJxYLToH+DJwI3BRtewi4CPV5RuBX6tmL54BPFpvQUqStHpIv/c/A++LiDXAV4HXUAvV6yPiYuAB4IJq3Y8DLwHuAx6v1pUkCRhSkGXmNmBDk5vOabJuAq/te1GSpCJ1FGQR8XzgR4Gn15dl5nv7VZQkSZ1aMsgi4o3AC6kF2cepHaD8GcAgkyQNXSeTPV5OreX39cx8DbUzcTytr1VJktShToJsPjP3Ak9VZ+V4mNpBzZIkDV0n+8i2RMQ08E7gduC7wOf7WpUkSR1aMsgy8zeri++IiE8AP5CZd/a3LEmSOrNka7E6EPnVEfH7mXk/MBcRp/W/NEmSltbJPrK/AH4KeGV1/TvAn/etIkmSutDJPrLTM/PUiNgKkJmPVGfkkCRp6DoZkS1ExATVGecjYh2wt69VSZLUoU6C7M+ADwNHRsQfUjsY+n/0tSpJkjrUyazF90XE7dQOig5gY2be3ffKJEnqQNsgi4hVwJ2Z+XzgnsGUJElS59q2FqszetwREccOqB5JkrrSyazF5wB3RcTngceqZZmZ5/evLEmSOtNJkF3ZcDmAn2H/MWWSJA3VkrMWM/MfgUeBlwJ/TW3Sxzv6W5YkSZ1pOSKLiH8DvILa6OtbwHVAZOZZA6pNkqQltWst3gP8M/ALmXkfQERcOpCqJEnqULvW4i8BXwdujYh3RkT9ODJJkkZGyyDLzA9n5oXAScCngUuBZ0fE2yPiRQOqT5KktjqZ7PFYZr4vM38eOBrYBlzW98okSepAJ+da3Cczd2fmX2bm2f0qSJKkbnQVZJIkjRqDTJJUNINMklQ0g0ySVDSDTJJUNINMklQ0g0ySVDSDTJJUNINMklQ0g0ySVDSDTJJUNINMklQ0g0ySVDSDTJJUNINMklQ0g0ySVDSDTJJUNINMklQ0g0ySVDSDTJJUNINMklS0oQVZRExExNaI+Pvq+vERcVtEfCUirouINdXyp1XX76tuP25YNUuSRs8wR2S/DdzdcP2PgLdm5gnAI8DF1fKLgUcy80eAt1brSZIEDCnIIuJo4KXAu6rrAZwNfLBa5VpgY3X5/Oo61e3nVOtLkjS0EdmfAv8V2FtdfyYwl5lPVdd3ADPV5RngQYDq9ker9Q8QEZdExJaI2LJr165+1i5JI2Wlb/8GHmQR8fPAw5l5e+PiJqtmB7ftX5B5TWZuyMwN69at60GlklSGlb79Wz2E33km8IsR8RLg6cAPUBuhTUfE6mrUdTSws1p/B3AMsCMiVgPPAHYPvmxJ0iga+IgsMy/PzKMz8zjgFcCnMvNXgFuBl1erXQR8pLp8Y3Wd6vZPZeZBIzJJ0so0SseR/S7w+oi4j9o+sHdXy98NPLNa/nrgsiHVJ0kaQcNoLe6TmZ8GPl1d/ipwWpN1ngAuGGhhkqRijNKITJKkrhlkkqSiGWSSpKIZZJKkohlkkqSiGWSSpKIZZJKkohlkkqSiGWSSpKIZZJKkohlkkqSiGWSSpKIZZJKkohlkkqSiGWSSpKIZZJKkohlkkqSiGWSSpKIZZJKkohlkkqSiGWSSpKIZZJKkohlkkqSirR52AZL6b/PWWa6+6V52zs1z1PQUm849kY3rZ4ZdltQTBpk05jZvneXyG7Yzv7AHgNm5eS6/YTuAYTaGdj/25LBLGDhbi9KYu/qme/eFWN38wh6uvuneIVUk9ZZBJo25nXPzXS2XSmOQSWPuqOmprpZLpTHIpDG36dwTmZqcOGDZ1OQEm849cUgVSb3lZA9pzNUndDhrUePKIJNWgI3rZwyuFeKItWuGXcLA2VqUJBXNIJMkFc0gkyQVzSCTJBXNIJMkFc0gkyQVzSCTJBXNIJMkFc0gkyQVzTN7SH3kF1pK/WeQSX3iF1pqGPxiTUk94xdaSoMx8BFZRBwDvBf4QWAvcE1mvi0ijgCuA44D7gd+OTMfiYgA3ga8BHgc+PXM/OKg65baadZC9AstpcEYxojsKeB3MvN5wBnAayPiR4HLgFsy8wTgluo6wIuBE6qfS4C3D75kqbV6C3F2bp5kfwtx+rDJpuvXv9By89ZZzrzqUxx/2cc486pPsXnr7ACrlsbHwIMsMx+qj6gy8zvA3cAMcD5wbbXatcDG6vL5wHuz5nPAdEQ8Z8BlSy21aiFm0vILLVuFn2EmdW+o+8gi4jhgPXAb8OzMfAhqYQccWa02AzzYcLcd1bLFj3VJRGyJiC27du3qZ9nSAVq1Ch+dX+AtLzuZmekpApiZnuItLzuZjetn3H+mnmrc/n1nbvewyxm4oc1ajIjvAz4EvC4zv13bFdZ81SbL8qAFmdcA1wBs2LDhoNulfjlqeorZJmF21PRUyy+0XGn7zzwMob8at3/Pfd4LVtz2bygjsoiYpBZi78vMG6rF36i3DKt/H66W7wCOabj70cDOQdUqLWXTuSe2bCG2Ut9P1unyktlGVb8NPMiqWYjvBu7OzD9puOlG4KLq8kXARxqW/1rUnAE8Wm9BSqNg4/qZli3EVpYTfqWyjap+G0Zr8UzgV4HtEbGtWvZ7wFXA9RFxMfAAcEF128epTb2/j9r0+9cMtlxpaa1aiO3WB3rebhvFFt5Ka6Nq8AYeZJn5GZrv9wI4p8n6Cby2r0VJQ9Bt+C1lVM8k0m4fotQLntlDGhOj2sJbSW1UDYfnWpTGxKi28PrVRpXqDDJpTIxyC6/XbVSpka1FaRlG8fRStvC0Ujkik7o0qpMqbOFppTLIpC61m1Qx7NCwhaeVyNai1KVRnVQhARyxds2wSxg4g0zq0ko6vZRUAoNM6pKTKqTR4j4yqUtOqpBGi0EmLYOTKqTRYWtRklQ0g0ySVDSDTJJUNINMklQ0g0ySVDRnLUp9Morf1rwc4/I8NL4MMqkPRvXEwt0al+eh8WZrUeqDUf225m6Ny/NYSXY/9uSwSxg4R2RSH4zLiYVH4XnY2tRSDDKpD0b525q70evn0W0o2dpUJ2wtSn0wLicW7uXzqIfS7Nw8yf5QesPm7S2/bdvWpjrhiEzqg25PLDyq7bNeniC5VSi973MPkNX1xSOuUWhtavQZZFKfdHpi4VFvn/XqBMmtwicXXW/8tu1xadGqv2wtSkO2Utpn3YRPPfTGpUWr/nJEJjHc1l4v22f9fB6H+tibzj3xgJEnQHDwiAz2h57f/aZOGGRa8Ybd2utV+6yfz6MXj90slM46aR0fun32gHBbPOLyu9+0FINMI6/fo6V2rb1BbECbjVSW0z7r5/Po1WM3C6UNP3RE11PyHaGpkUGmkTaI0dKwZ8bVn8eVH72LRx5fAOBpq7vffd3P59HPx+5mxDXs0bNGk5M9NNIGMRGiVQtv0DPjnljYu+/y3PwCl9+w/YBjqpbSzfPYvHW25bFbh/rY/bRSJsYcqvff9sCwSxgog0xL6naj10uDGC2Nwsy4XmygzzppXUfLWx2Y3O7/dRReIxj+6Fmjydai2hp2K6efxxE17mt5xtQkT59cxdzjC33f79JsH08vNtC33rOro+VXfvSurvd3jcrswXZ/D+47W7kMMrU1LhMhFlsc0HPzC0xNTvDWC0/p6/Nq9cHgGVOTzM0vHLT+qgiOv+xjHW2YOwnDzVtn9+2H6/T+dYOcPdgqlFr9PZx10jr3na1gBpnaGnYrpxcjgWYbxV4FdLejgFa/9+mTq5ianDjotj1ZO8qqkw1zJ6PXdq3KUTlbRiddgH79f/aTI8b+McjUVicbx369QRc/7nJGS5u3zrLpg3ewsGd/IDReX6ybgG63wYXm4dvq8eceX+CtF56y7z6rIvaFWN1SG+ZORq/tnt+onC1jqVBqNjK89LptTR9rVPadDbtFP+6c7KG2ltrJv5yJA53oxeNu3jrLpddvOyi0FvYkq6L5faYPm+z48VttcK/86F0H1f6667ax/k2fbPn4R01PsXH9DJ+97Gz+9aqXsje7D9qN62d4y8tOZmZ6igBmpqd4y8tOPmBD2WrUNT01OTIb1OV0AUZlVmUrw5ht+f7bHlgxsxcdkamtpVp7y23pLDWKO9RWUT0IW+QBexMmJ+KgkPvuE0/tC8v/9uHtPPZkrYYAfuWMY3nzxpP3rdtqw9pqH9Qjjy+0DNDFMwtbjYRXReyrr9nrt9R+rFaniZqbX+DMqz41Eu2u5Uzw6de+1F4Zdot+3BlkA/aGzdv5wG0PsieTiQheefoxB2wcl6Pfvfd2G8dmG5x2y6GzNsuhvvGbBeFia9esPmiCxcLe5MqP3sW3n3iKPXv3h1wCf/O52qfb+v9Xqw1uO3tbBOut9+w6aBZls6Ddk8mmD94BWasVumtTNX4Aqdfe6itUhmU5oTQqsyqb2bx1tmmrGEZnxFg6g6yPFgfMcc+c4rP/snvf7XsyD9o4Lud3DLP3PtHiDToRLYYedDbaOtRp90sF3vTUJI82mSUIrUdUAB+47cF9/1fNNrjLNTs3z+uv37Yv6ObmF1r2/Zvt3+tmtFpf59LrtrX9CpVhWW4ojeI5Gevvz2bvkVEaMZbOIOuTZpMMWn16b9w4dmuQs7WajfyavUGBlsuhs9HWobaK2o2WJlcFV/zijx0wKulU4/NavMFt9am7U4tHa3ubr9bS7Nw8m7fOLvn/vnnrLL9z/R1NzzoP/W13ddo9GMVQWo5WnYGJiIP2X2r5DLI+ufKjd7WcGbfYoWz8ltOCW04rstXIb7rF8U8zbUZOnYy2DrVVdNZJ6w745uG6ww+b5I2/8GNsXD/Dlq/t3jcibjS5ChZapMjikWbjBvf4yz62ZF2TE3FAW7DXLr1uG3+35QHu/9Z809et3QihrpNRby//hqD8mXutXo9W78O9mcU/51FikNGffUzt2lOLTVQ78JdTQ7ctuOVuTLo5/ql+gOopV37ygJCrh8hZJ61rGiCLJzw0hsTmrbNc+dG7eF01zXp6apIrfvHHmta8eessH7p9tumI47A1+//kW50Jo1WIAZzx3MNb3rbUPrOJCE477nC+/NB3uvr76EbCAe3r+v/vlq/t5tZ7dnU0An3se0/xhs3b960fwb5JM2smgicXfUCrH9JwxY138eh86zOjdNI9aPc+qN82Oze/r6U9MwLfudbuPTUK33Bd8szFV51+bEfrRR7CaGBUbdiwIbds2dLRuov/CKG2IT7UYf9xHXw6rzvhyLXc/63HDxjBTU4EV7/8x5es4Q2btzcNhVdXM+wWvzEf+95TLUdQn73s7Ja/5/jLPtY0GAL2Hf/UuIFpZWJVsHdvNn2sxhoaJ8W0+vLFyVXBhacdw6337Dro4Nh2G+zJVcHVF/z4vlDs1to1E0xOrDpoo/2GzdubjgJHQavXsF8Wv4c2b51t+3rX/24W1zk1OcEv/cQMH7vzoZbhX///bHyv9CKQmj2PZs686lNN/97qIdvD7UvrHc8Nnvu8F+Sb//rvu33skbQoyFo+/2KCLCLOA94GTADvysyrWq3bTZC1+yNst2FfSjdB1srhh02y9fdf1Hadbt9ErQTwr1e9tOltm7fONp0YALWR0dqnre56X1M7EwEddmVVgOmpSb7zvQNngfZD/W8eYNPf3dG0fds4gls8S/TbTyw0nVW63A95AH964SlAz2ZTGmQtFNFajIgJ4M+BfwvsAL4QETdm5pcP9bF7fXxH/c3RC42fQLvtwc/OzfM719/R8f63BE658pP7RhlnnbSuo1bU3PxC0xHeoTDExkuv/z5aqR943u6DUGOr9f23PXDALNF2j9tuEk27lvLlN2znLS87+ZA+FGtppZzZ4zTgvsz8amY+CfwtcH4vHriXZwRoPBtFL7U7y0WrOoPuJ5HMzS/se/y/+dwDPX8e0iAs9UFofmEPf/O5B1oe09dMu7PKbDr3RCZaHOnud6UNRilBNgM82HB9R7XskPXye5Y6OQi3G9NTky0ft/4GaVb/oPeHSOOuXSBtXD/D3jap6Nk7+q+I1iLNe6MH/OVExCXAJQDHHtvZTBfo7RkBevkHWz/Wqd3j7pybb1q/Iymp99q9v9t9cBzEDMXF279OZ/uNi1KCbAdwTMP1o4GdjStk5jXANVCb7NHNg/fq4Mt2ITIRwRnPPfyAqdGtLJ5SvNQU3sX1t5oAIqnWcXliYU/XXYt2gdRutu4gzt5xKNu/cVBKa/ELwAkRcXxErAFeAdw45JoO0qpN+acXnsK/vOUlvO8//BSvPqP1J6VV1GY5ffaysw8Ipm7bn83Wl0pwwpFrObzDbyCYXBWccOTapred+cNH7PsWgMMPm2R6avKAbwT4lTbvw2aW2t3wytOPabr8zB8+wgOfB6CIEVlmPhURvwXcRG36/Xsy864hl3WQTtqUb954Mht+6Ah+74Y7ebzhyNupyVW85WUvaHm6nqUet9X6zUZma9dM8NiTe1gV+0+LdNjkKtasnjho1mJ9anJEbRZls/1vz/7+NayemFhyFFgflTYeELyKg0/FVP90O93we9Ubq1cFTx3iNPjGYxSvuPGutjP+2v2+pU6aXT8Ivtn/f+MB8cs5EXf9PbL4fht+6IhlHXRd/329PiG4OlPMcWTd6OY4MkkqREfHkY3x9q/l8y+ltShJUlMGmSSpaAaZJKloBpkkqWgGmSSpaAaZJKloBpkkqWgGmSSpaAaZJKloY3lmj4jYBXxt2HW08Szgm8MuokvWPBgl1gxl1l1azd/MzPOWWikiPtHJeuNkLINs1EXElszcMOw6umHNg1FizVBm3SXWrOZsLUqSimaQSZKKZpANxzXDLmAZrHkwSqwZyqy7xJrVhPvIJElFc0QmSSqaQSZJKppBNkARcX9EbI+IbRExsl/hGhHviYiHI+JLDcuOiIibI+Ir1b+HD7PGxVrUfEVEzFav97aIeMkwa1wsIo6JiFsj4u6IuCsifrtaPrKvdZuaR/a1joinR8TnI+KOquYrq+XHR8Rt1et8XUSsGXatWh73kQ1QRNwPbMjMkT4IMyJ+Fvgu8N7MfH617H8CuzPzqoi4DDg8M393mHU2alHzFcB3M/OPh1lbKxHxHOA5mfnFiPh+4HZgI/DrjOhr3abmX2ZEX+uICGBtZn43IiaBzwC/DbweuCEz/zYi3gHckZlvH2atWh5HZDpIZv4TsHvR4vOBa6vL11LbeI2MFjWPtMx8KDO/WF3+DnA3MMMIv9Ztah5ZWfPd6upk9ZPA2cAHq+Uj9TqrOwbZYCXwyYi4PSIuGXYxXXp2Zj4EtY0ZcOSQ6+nUb0XEnVXrcWRadItFxHHAeuA2CnmtF9UMI/xaR8RERGwDHgZuBv4FmMvMp6pVdjDigazWDLLBOjMzTwVeDLy2aoepf94O/DBwCvAQ8L+GW05zEfF9wIeA12Xmt4ddTyea1DzSr3Vm7snMU4CjgdOA5zVbbbBVqVcMsgHKzJ3Vvw8DH6b2hirFN6r9I/X9JA8PuZ4lZeY3qg3YXuCdjODrXe2z+RDwvsy8oVo80q91s5pLeGTcRQ0AAAOzSURBVK0BMnMO+DRwBjAdEaurm44Gdg6rLh0ag2xAImJttXOciFgLvAj4Uvt7jZQbgYuqyxcBHxliLR2ph0Hl3zFir3c1CeHdwN2Z+ScNN43sa92q5lF+rSNiXURMV5engJ+jtm/vVuDl1Woj9TqrO85aHJCIeC61URjAauD9mfmHQyyppYj4APBCal9z8Q3gjcBm4HrgWOAB4ILMHJnJFS1qfiG1VlcC9wP/sb7vaRRExM8A/wxsB/ZWi3+P2j6nkXyt29T8Skb0tY6IF1CbzDFB7cP79Zn5puo9+bfAEcBW4NWZ+b3hVarlMsgkSUWztShJKppBJkkqmkEmSSqaQSZJKppBJkkq2uqlV5FGV0Q8E7iluvqDwB5gV3X9tMx8ciiFtRER/x74eGZ+fdi1SOPA6fcaG6N0tvuImMjMPS1u+wzwW5m5rYvHW91wXkBJDWwtamxFxEXV91Bti4i/iIhVEbE6IuYi4uqI+GJE3BQRp0fEP0bEV+vfoxURvxERH65uvzci3tDh4745Ij4PnBYRV0bEFyLiSxHxjqi5kNqBw9dV918TETsazjxxRkT8Q3X5zRHxlxFxM/BX1e/4k+p33xkRvzH4V1UaPQaZxlJEPJ/aqZJ+ujpZ7GrgFdXNzwA+WZ3A+UngCuAc4ALgTQ0Pc1p1n1OBV0XEKR087hcz87TM/H/A2zLzJ4GTq9vOy8zrgG3AhZl5Sgetz/XAL2TmrwKXAA9n5mnAT1I78fSxy3l9pHHiPjKNq5+jtrHfUjs9IFPAg9Vt85l5c3V5O/BoZj4VEduB4xoe46bMfAQgIjYDP0PtPdPqcZ9k/2nIAM6JiE3A06mdOut24P92+Tw+kplPVJdfBDwvIhqD8wRqp7GSViyDTOMqgPdk5n8/YGHtbOeNo6C9wPcaLje+JxbvQM4lHnc+q53OEXEY8L+BUzNzNiLeTC3QmnmK/d2Rxes8tug5/WZm3oKkfWwtalz9A/DLEfEsqM1uXEYb7kURMV2F0vnAZ7t43ClqwfjN6lsPfqnhtu8A399w/X7gJ6rLjestdhPwm/WvHomIE6uzuUsrmiMyjaXM3B4RVwL/EBGrgAXgP9Hdd059Bng/tS+M/D/1WYadPG5mfisirqX2dSZfY/+3KAP8FfCuiJinth/uCuCdEfF14PNt6vlLamfE31a1NR+mFrDSiub0e6mJakbg8zPzdcOuRVJ7thYlSUVzRCZJKpojMklS0QwySVLRDDJJUtEMMklS0QwySVLR/j9i2r3T23Ke+gAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 432x432 with 3 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot with correct axis labels [3pts]\n",
    "ax = sns.jointplot(x=FF['temp'],y=FF['area'])\n",
    "ax.ax_joint.set_xlabel('Temperature')\n",
    "ax.ax_joint.set_ylabel('Area')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Written answer: We can see the area has a very skewed distribution, with two events burning a large area. It is not completely clear if temperature and area are related given this skewness, but they appear to be positively correlated.** [2pts]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.4 Logarithmic transformation (X / 3 pts)\n",
    "\n",
    "Given the distribution of area, the original researchers proposed **using the logarithm of the area instead of the original variable**. Calculate this new target variable (name it ```LogArea```) so that $LogArea = log(area + 1)$.\n",
    "\n",
    "Now, create a joint plot again of the distribution between the temperature and your newly created variable ```LogArea```. Written answer: Do you see any relationship more clearly now? Do you think it was a good idea to make this transformation? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x432 with 3 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Create the logarithmic transformation [1pt]\n",
    "FF['LogArea'] = np.log(FF['area'] + 1)\n",
    "\n",
    "# Plot relationship [1pt]\n",
    "ax = sns.jointplot(x=FF['temp'], y=FF['LogArea'])\n",
    "ax.ax_joint.set_xlabel('Temperature')\n",
    "ax.ax_joint.set_ylabel('Area (log)')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Written answer: The plot does look much better now and there seems to be a slight positive trend.** [1pt]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 1.5: Regression comparison (X / 15 pts)\n",
    "\n",
    "Now we will compare the performance of a linear regressor with the two different target variables. For this:\n",
    "\n",
    "a. Create a train / test split using 30% of the data as a test set. Use a `random_state` of 1 if using `train_test_split` (2 pts).\n",
    "\n",
    "b. Create a regression of all variables (X) versus the area variable (y) without transformation on the training data only (6 pts).\n",
    "\n",
    "c. Create a regression of all variables (X) versus the log-transformed area variable (y) on the training data only (3 pts).\n",
    "\n",
    "d. Calculate and report the mean absolute error of both models when predicting the variable `area` in the test set. Make sure you transform the prediction of the model in c) from log(area) to an area first! Written answer: Which one is the most accurate model? Why do you think this happens? (4 pts - 2pts for results, 2 pts for written answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The MAE of the area regression is 21.175 and the MAE of the log-area regression is 13.285\n"
     ]
    }
   ],
   "source": [
    "# Define train and test\n",
    "pred_vars = np.r_[0:9, 11:28]\n",
    "targets = np.r_[10, 28]\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(FF.iloc[:, pred_vars],\n",
    "                                                    FF.iloc[:, targets],\n",
    "                                                    test_size=0.3, \n",
    "                                                    random_state=1)\n",
    "\n",
    "# Linear regressions\n",
    "area_reg = LinearRegression()\n",
    "logarea_reg = LinearRegression()\n",
    "\n",
    "# Fit\n",
    "area_reg.fit(x_train, y_train.iloc[:,0])\n",
    "logarea_reg.fit(x_train, y_train.iloc[:,1])\n",
    "\n",
    "# Predict\n",
    "pred_area = area_reg.predict(x_test)\n",
    "pred_logarea = logarea_reg.predict(x_test)\n",
    "pred_logarea = np.exp(pred_logarea) - 1\n",
    "\n",
    "# Report Mean absolute error\n",
    "mae_area = mean_absolute_error(y_test.iloc[:, 0], pred_area)\n",
    "mae_logarea = mean_absolute_error(y_test.iloc[:, 0], pred_logarea)\n",
    "\n",
    "print('The MAE of the area regression is %.3f and the MAE of the log-area regression is %.3f' % (mae_area, mae_logarea))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Written answer: The logarithmic model is clearly the more accurate model, with an error three times as small as the model without a logarithmic transform. For the untransformed data, the distribution is very sweked, such that the model fit (with minimizes the squared error) will be very sensitive to the large, outlying values. This makes the predictions very variable. For the model trained on log-transformed, this effect is mitigated, such that the model makes less variable predictions.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 2: Build a classifier to distinguish major and minor forest fires (35 points)\n",
    "\n",
    "For the second task we will study whether we can differentiate a major from a minor forest fire. For this, we first need to decide what exactly a major forest fire is and test whether we can significantly differentiate one versus the other."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 2.1: Building the new target variable. (X / 5 pts)\n",
    "\n",
    "Let's start by defining a major burn as any forest fire that burns more than 1 ha. Reimport the data and now create the dummy variables without dropping any of the columns (as we will regularize). Then create a binary variable that represents whether a forest fire is larger than one ha or not. Written answer: Which percentage of fires are classified as major this way? \n",
    "\n",
    "Then create a set of histograms or distribution plots (you can use for example `displot` in seaborn) that shows the the distribution of the minor and major forest fires as a function of all major predictor variables (`X`, `Y`, `FFMC`, `DMC`, `DC`, `ISI`, `temp`, `RH`, `wind`, `rain`). Skip the dummy variables. What percentage of cases are classified as a major fire this way? Looking at the plots, do you think you can create a model differentiating between major and minor forest fires?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>X</th>\n",
       "      <th>Y</th>\n",
       "      <th>FFMC</th>\n",
       "      <th>DMC</th>\n",
       "      <th>DC</th>\n",
       "      <th>ISI</th>\n",
       "      <th>temp</th>\n",
       "      <th>RH</th>\n",
       "      <th>wind</th>\n",
       "      <th>rain</th>\n",
       "      <th>...</th>\n",
       "      <th>month_10</th>\n",
       "      <th>month_11</th>\n",
       "      <th>month_12</th>\n",
       "      <th>day_1</th>\n",
       "      <th>day_2</th>\n",
       "      <th>day_3</th>\n",
       "      <th>day_4</th>\n",
       "      <th>day_5</th>\n",
       "      <th>day_6</th>\n",
       "      <th>day_7</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>517.000000</td>\n",
       "      <td>517.000000</td>\n",
       "      <td>517.000000</td>\n",
       "      <td>517.000000</td>\n",
       "      <td>517.000000</td>\n",
       "      <td>517.000000</td>\n",
       "      <td>517.000000</td>\n",
       "      <td>517.000000</td>\n",
       "      <td>517.000000</td>\n",
       "      <td>517.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>517.000000</td>\n",
       "      <td>517.000000</td>\n",
       "      <td>517.000000</td>\n",
       "      <td>517.000000</td>\n",
       "      <td>517.000000</td>\n",
       "      <td>517.000000</td>\n",
       "      <td>517.000000</td>\n",
       "      <td>517.000000</td>\n",
       "      <td>517.000000</td>\n",
       "      <td>517.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>4.669246</td>\n",
       "      <td>4.299807</td>\n",
       "      <td>90.644681</td>\n",
       "      <td>110.872340</td>\n",
       "      <td>547.940039</td>\n",
       "      <td>9.021663</td>\n",
       "      <td>18.889168</td>\n",
       "      <td>44.288201</td>\n",
       "      <td>4.017602</td>\n",
       "      <td>0.021663</td>\n",
       "      <td>...</td>\n",
       "      <td>0.029014</td>\n",
       "      <td>0.001934</td>\n",
       "      <td>0.017408</td>\n",
       "      <td>0.143133</td>\n",
       "      <td>0.123791</td>\n",
       "      <td>0.104449</td>\n",
       "      <td>0.117988</td>\n",
       "      <td>0.164410</td>\n",
       "      <td>0.162476</td>\n",
       "      <td>0.183752</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>2.313778</td>\n",
       "      <td>1.229900</td>\n",
       "      <td>5.520111</td>\n",
       "      <td>64.046482</td>\n",
       "      <td>248.066192</td>\n",
       "      <td>4.559477</td>\n",
       "      <td>5.806625</td>\n",
       "      <td>16.317469</td>\n",
       "      <td>1.791653</td>\n",
       "      <td>0.295959</td>\n",
       "      <td>...</td>\n",
       "      <td>0.168007</td>\n",
       "      <td>0.043980</td>\n",
       "      <td>0.130913</td>\n",
       "      <td>0.350548</td>\n",
       "      <td>0.329662</td>\n",
       "      <td>0.306138</td>\n",
       "      <td>0.322907</td>\n",
       "      <td>0.371006</td>\n",
       "      <td>0.369244</td>\n",
       "      <td>0.387657</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>18.700000</td>\n",
       "      <td>1.100000</td>\n",
       "      <td>7.900000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.200000</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>3.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>90.200000</td>\n",
       "      <td>68.600000</td>\n",
       "      <td>437.700000</td>\n",
       "      <td>6.500000</td>\n",
       "      <td>15.500000</td>\n",
       "      <td>33.000000</td>\n",
       "      <td>2.700000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>91.600000</td>\n",
       "      <td>108.300000</td>\n",
       "      <td>664.200000</td>\n",
       "      <td>8.400000</td>\n",
       "      <td>19.300000</td>\n",
       "      <td>42.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>7.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>92.900000</td>\n",
       "      <td>142.400000</td>\n",
       "      <td>713.900000</td>\n",
       "      <td>10.800000</td>\n",
       "      <td>22.800000</td>\n",
       "      <td>53.000000</td>\n",
       "      <td>4.900000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>9.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>96.200000</td>\n",
       "      <td>291.300000</td>\n",
       "      <td>860.600000</td>\n",
       "      <td>56.100000</td>\n",
       "      <td>33.300000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>9.400000</td>\n",
       "      <td>6.400000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                X           Y        FFMC         DMC          DC         ISI  \\\n",
       "count  517.000000  517.000000  517.000000  517.000000  517.000000  517.000000   \n",
       "mean     4.669246    4.299807   90.644681  110.872340  547.940039    9.021663   \n",
       "std      2.313778    1.229900    5.520111   64.046482  248.066192    4.559477   \n",
       "min      1.000000    2.000000   18.700000    1.100000    7.900000    0.000000   \n",
       "25%      3.000000    4.000000   90.200000   68.600000  437.700000    6.500000   \n",
       "50%      4.000000    4.000000   91.600000  108.300000  664.200000    8.400000   \n",
       "75%      7.000000    5.000000   92.900000  142.400000  713.900000   10.800000   \n",
       "max      9.000000    9.000000   96.200000  291.300000  860.600000   56.100000   \n",
       "\n",
       "             temp          RH        wind        rain  ...    month_10  \\\n",
       "count  517.000000  517.000000  517.000000  517.000000  ...  517.000000   \n",
       "mean    18.889168   44.288201    4.017602    0.021663  ...    0.029014   \n",
       "std      5.806625   16.317469    1.791653    0.295959  ...    0.168007   \n",
       "min      2.200000   15.000000    0.400000    0.000000  ...    0.000000   \n",
       "25%     15.500000   33.000000    2.700000    0.000000  ...    0.000000   \n",
       "50%     19.300000   42.000000    4.000000    0.000000  ...    0.000000   \n",
       "75%     22.800000   53.000000    4.900000    0.000000  ...    0.000000   \n",
       "max     33.300000  100.000000    9.400000    6.400000  ...    1.000000   \n",
       "\n",
       "         month_11    month_12       day_1       day_2       day_3       day_4  \\\n",
       "count  517.000000  517.000000  517.000000  517.000000  517.000000  517.000000   \n",
       "mean     0.001934    0.017408    0.143133    0.123791    0.104449    0.117988   \n",
       "std      0.043980    0.130913    0.350548    0.329662    0.306138    0.322907   \n",
       "min      0.000000    0.000000    0.000000    0.000000    0.000000    0.000000   \n",
       "25%      0.000000    0.000000    0.000000    0.000000    0.000000    0.000000   \n",
       "50%      0.000000    0.000000    0.000000    0.000000    0.000000    0.000000   \n",
       "75%      0.000000    0.000000    0.000000    0.000000    0.000000    0.000000   \n",
       "max      1.000000    1.000000    1.000000    1.000000    1.000000    1.000000   \n",
       "\n",
       "            day_5       day_6       day_7  \n",
       "count  517.000000  517.000000  517.000000  \n",
       "mean     0.164410    0.162476    0.183752  \n",
       "std      0.371006    0.369244    0.387657  \n",
       "min      0.000000    0.000000    0.000000  \n",
       "25%      0.000000    0.000000    0.000000  \n",
       "50%      0.000000    0.000000    0.000000  \n",
       "75%      0.000000    0.000000    0.000000  \n",
       "max      1.000000    1.000000    1.000000  \n",
       "\n",
       "[8 rows x 30 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import thte data again without removing the redundant dummy variable [1pts]\n",
    "FF = pd.read_csv('forestfires.csv')\n",
    "FF = pd.get_dummies(FF, drop_first=False, columns=['month','day'])\n",
    "FF.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 47.00 % of cases classified as a major fire when using 1 ha as a cutoff\n"
     ]
    }
   ],
   "source": [
    "# Define the binary variable and report number [1pts]\n",
    "\n",
    "FF['major_fire'] = (FF['area'] > 1) * 1 # Turns into integer.\n",
    "print('There are %.2f %% of cases classified as a major fire when using 1 ha as a cutoff' % (np.mean(FF['major_fire']) * 100.0))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'seaborn' has no attribute 'displot'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-7cb7dd7bf1f1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Create the distribution plots or histograms for each regressor [2 pts]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mcol_id\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mFF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0msns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdisplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mFF\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcol_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhue\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"major_fire\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkind\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'kde'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m: module 'seaborn' has no attribute 'displot'"
     ]
    }
   ],
   "source": [
    "# Create the distribution plots or histograms for each regressor [2 pts]\n",
    "for col_id in FF.columns[0:10]:\n",
    "    sns.displot(data=FF, x=col_id, hue=\"major_fire\", kind='kde')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Written answer: Most plots are very similar, but some have some differences so it should be possible to predict the best model.** [1pt]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 2.2: Ridge regression (X / 10 pts)\n",
    "\n",
    "Now we need to put your theory from the previous written answer to the test. Your objective is to train a logistic regression using your newly created variable. For this:\n",
    "\n",
    "a. Create a train / test split of the dataset reserving 30% for the test set. Use `random_state = 1` if using `train_test_split`. [2 pts]\n",
    "\n",
    "b. Create a pipeline that first normalizes your training data and then trains a logistic regression **using Ridge penalty with a tolerance of 0.001 and sufficient iterations for the model to converge**. Use a C of 0.006 (Ridge parameter). [2pts]\n",
    "\n",
    "\n",
    "c. Fit the model to the training data. Show the coefficients and what variable they are related to. [3pts]. Written answer: Based on these coefficients, which variable has the largest influence on the prediction[1pt]? In the context of this model, does wind speed lead to lower or higher risk of major fires[1pt]? How important is the influence of the day of the week and which of the days of the week are the riskiest[1pt]?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# a. Define predictive variables\n",
    "pred_vars = np.r_[0:9, 11:30]\n",
    "target = np.r_[30]\n",
    "\n",
    "# Create train and test\n",
    "x_train, x_test, y_train, y_test = train_test_split(FF.iloc[:, pred_vars],\n",
    "                                                    FF.iloc[:, target],\n",
    "                                                    test_size=0.3, \n",
    "                                                    random_state=1)\n",
    "\n",
    "# Correct warning\n",
    "y_train = y_train.values.ravel()\n",
    "y_test = y_test.values.ravel()\n",
    "\n",
    "# b. Pipeline\n",
    "\n",
    "LogFF = LogisticRegression(penalty='l2', solver='saga', tol=0.001, \n",
    "                           max_iter=1000, C=0.006)\n",
    "\n",
    "LogPipeline = Pipeline(steps=[('Standardize', StandardScaler()),\n",
    "                              ('Logistic', LogFF)]\n",
    "                      )\n",
    "\n",
    "# c. Training\n",
    "LogPipeline.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LogCoefs = pd.DataFrame({'variables': FF.columns[pred_vars].values, \n",
    "                         'coefficients': LogPipeline._final_estimator.coef_[0]})\n",
    "LogCoefs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Written answer: The largest coefficient is month_12 (December), which therefore is the most influential variable (after standarization). Higher wind speeds increase the risk of a major fire. The coefficients for the days of the week are all fairly small, but there seems to be Wednesdays and Saturdays are riskier than the other days.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 2.3: Validating your model. (X / 5 pts)\n",
    "\n",
    "Now we will begin validating our model. Apply your results to the test set you created. Report the accuracy (leaving the default cutoff of 0.5), plot the ROC curve, and calculate the AUC. Comment on the performance of your model. How well does the model differentiate between major and minor forest fires?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply pipeline to the test set. [1pts]\n",
    "log_class_test = LogPipeline.predict(x_test)\n",
    "\n",
    "\n",
    "# Calculate the precision measures. I am using the function from A.3 [1pts]\n",
    "def compute_performance(yhat, y, classes):\n",
    "    # First, get tp, tn, fp, fn\n",
    "    tp = sum(np.logical_and(yhat == classes[1], y == classes[1]))\n",
    "    tn = sum(np.logical_and(yhat == classes[0], y == classes[0]))\n",
    "    fp = sum(np.logical_and(yhat == classes[1], y == classes[0]))\n",
    "    fn = sum(np.logical_and(yhat == classes[0], y == classes[1]))\n",
    "\n",
    "    print(f\"tp: {tp} tn: {tn} fp: {fp} fn: {fn}\")\n",
    "\n",
    "    # Accuracy\n",
    "    acc = (tp + tn) / (tp + tn + fp + fn)\n",
    "\n",
    "  \n",
    "    print(\"Accuracy:\", round(acc, 3))\n",
    "\n",
    "\n",
    "compute_performance(log_class_test, y_test,\n",
    "                    LogPipeline._final_estimator.classes_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ROC for all-variable classifier [2pts]\n",
    "y_test_prob = LogPipeline.predict_proba(x_test)\n",
    "fpr, tpr, thresholds = roc_curve(y_test, y_test_prob[:, 1], pos_label=1)\n",
    "log_test_auc = auc(fpr, tpr)\n",
    "\n",
    "# Plot curve\n",
    "plot_roc_curve(LogPipeline, x_test, y_test)\n",
    "plt.show()\n",
    "print('The AUC of the curve is %.3f' % log_test_auc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Written answer: The model is not able to predict the major fires very well. It is better than random, but it is not clear the results are useful.** [1pts]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 2.4: A bootstrapped AUC measure. (X / 15 pts)\n",
    "\n",
    "Now we want to estimate a bootstrapped AUC. Create a bootstrap measure over the training set, with 100 runs, training your pipeline and calculating the AUC each time. Be careful that you must calculate the AUC in the corresponding \"test set\" of the bootstrapped sample, that is, calculate the ROC curve over the elements that were not selected in the sample.\n",
    "\n",
    "A useful function for this is [Panda's `isin` function](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.Index.isin.html) that returns a vector showing if the index is in a set. You must select the elements of your original data that are NOT in the index of your sample. You use this function in the following way: if you have a dataset called ```sample``` with a sample of the original dataset called ```data```, then the following code creates a test set with the elements in ```data``` that are not in ```sample```:\n",
    "\n",
    "```\n",
    "test = data[~data.index.isin(sample.index.values)]\n",
    "```\n",
    "\n",
    "After you have calculated the bootstrapped AUC, plot the distribution you obtained and calculate the standard deviation of the bootstrap samples. Assuming a normal distribution of the estimated AUC, construct a 95% confidence for the AUC measure you obtained in Question 2.3. (hint: on a standard normal distribution 95% of the probability mass is between -1.96 and +1.96). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Running the bootstrap. [7pts]\n",
    "def BootstrapPred(data, numboot=100):\n",
    "    LogFF = LogisticRegression(penalty='l2', solver='saga', tol=0.001,\n",
    "                               max_iter=1000, C=0.001)\n",
    "    LogPipeline = Pipeline(steps=[('Standardize', StandardScaler()),\n",
    "                                  ('Logistic', LogFF)]\n",
    "                          )\n",
    "    n = len(data)\n",
    "\n",
    "    # Storing objects\n",
    "    auc_out = np.zeros(numboot)\n",
    "    fprs_out = []\n",
    "    tprs_out = []\n",
    "    thresholds_out = []\n",
    "\n",
    "    for i in range(numboot):\n",
    "        d = data.sample(n, replace=True)\n",
    "        # Create test set\n",
    "        selection = data.index.isin(d.index.values)\n",
    "        test = data[~selection]\n",
    "        # This line controls the rare case where every element is selected. \n",
    "        # Not necessary to add in midterm\n",
    "        if len(test) == 0:\n",
    "            continue\n",
    "        # Fit pipeline\n",
    "        LogPipeline.fit(d.iloc[:, :-1], d.iloc[:, -1])\n",
    "        y_boot_prob = LogPipeline.predict_proba(test.iloc[:, :-1])\n",
    "        fpr, tpr, thresholds = roc_curve(test.iloc[:, -1],\n",
    "                                         y_boot_prob[:, 1], pos_label=1)\n",
    "        auc_out[i] = auc(fpr, tpr)\n",
    "        fprs_out.append(fpr)\n",
    "        tprs_out.append(tpr)\n",
    "        thresholds_out.append(thresholds)\n",
    "\n",
    "    return auc_out, fprs_out, tprs_out, thresholds_out\n",
    "\n",
    "\n",
    "# Calculate the ROC curve. Note I'm passing x_train and y_train together to be\n",
    "# consistent with assignment bootstrap implementation\n",
    "x_train_boot = x_train.copy()\n",
    "x_train_boot['y'] = y_train\n",
    "auc_out, fpr_out, tpr_out, thresholds_out = BootstrapPred(x_train_boot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the distribution [2pts]\n",
    "sns.histplot(auc_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the AUC deviations [2pts] \n",
    "auc_dev = np.std(auc_out)\n",
    "auc_dev"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the AUC confidence intervals. [2pts for correct normal approx, 2 pts for centering it on the real AUC]\n",
    "auc_min = log_test_auc - 1.96 * auc_dev\n",
    "auc_max = log_test_auc + 1.96 * auc_dev\n",
    "print('The confidence interval for the AUC is [%.3f, %.3f]' % (auc_min, auc_max))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 3: Build a regularized predictive model for temperature (35 points)\n",
    "\n",
    "Because temperature is such an important dterminant of fire danger, in this task we are trying to build a good seasonal model of the temperature observed in the park. \n",
    "\n",
    "### Question 3.1 (X / 5 pts)\n",
    "Reload the data set, so you get rid of your dummy variables and regain the original `month` and `day` variables. Make a `seaborn.stripplot` of Month on the x-axis and temperature on the y-axis. \n",
    "Written answer: What type of function would describe the relationship between average temperature and the month of the year best? Would a quadratic polynomial do well? For which month do you have the least observations? How many? \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make the plot [2pts]\n",
    "FF = pd.read_csv('forestfires.csv')\n",
    "sns.stripplot(x=FF.month, y=FF.temp)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Written answer: clearly the function is nonlinear with a peak in August - a simple quadratic function would capture some, but not all of the relationship [2pts]. November has only one observation - May has two.** [1pts] "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 3.2 (X / 5 pts)\n",
    "To model the relationship, you decide to encode the month of in terms of a fourier set (see lecture 6). \n",
    "\n",
    "Write a function `FourierExpansion(x,order)`, which takes a variable `x` scaled between 0 and 1, and returns a design matrix that has order times 2 columns. The first 2 columns should be set to: \n",
    "\n",
    "$sin(2 \\pi x)$\n",
    "\n",
    "$cos(2 \\pi x)$\n",
    "\n",
    "The next two columns: \n",
    "\n",
    "$sin(4 \\pi x)$\n",
    "\n",
    "$cos(4 \\pi x)$\n",
    "\n",
    "$...$\n",
    "\n",
    "and the last two columns: \n",
    "\n",
    "$sin(2 order \\pi x)$\n",
    "\n",
    "$sin(2 order \\pi x)$\n",
    "\n",
    "\n",
    "Test the function by calling it with \n",
    "\n",
    "`x=(np.array(range(12))+1)/12` and `order = 6`. \n",
    "\n",
    "Plot the design matrix as an image. \n",
    "\n",
    "Written answer: \n",
    "Which of the 12 columns in the design matrix can / should be removed before fitting? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fourier Expansion function  [3pts]\n",
    "def FourierExpansion(x,order):\n",
    "    x=x*2*np.pi\n",
    "    X=np.zeros((x.shape[0],0))\n",
    "    for i in range(order):\n",
    "        f = i+1; \n",
    "        X = np.c_[X,np.sin(f*x),np.cos(f*x)]\n",
    "    return X \n",
    "\n",
    "# Correct plot [1pt]\n",
    "x=(np.array(range(12))+1)/12\n",
    "X= FourierExpansion(x, 6)\n",
    "plt.imshow(X)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Written answer: The second to last column only contains zeros - as it is the sine on the highest frequency. The column therefore can and should be removed before fitting a linear model.** [1pt]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 3.3 (X / 5 pts)\n",
    "Now generate two different design matrices (models) to model the variation of temperature across the month of the year. \n",
    "* Model 1: use your function from Question 2.2 to generate a Fourier set (order 6) for month. Make sure you scale month between 0 and 1 before submitting to the function. \n",
    "* Model 2: use `pd.get_dummies` to generate a dummy or one-hot encoding of month. Because we will use this for an unregualized model, make sure you drop the first column. \n",
    "\n",
    "Fit the two unregularized linear model to the data and report the mean-square-error and the $R^2$ value for both models. If you have done everything correctly, the mse and $R^2$ values should be identical. Why is this? Hint: How many columns are in each design matrix and how many month in the year are there?  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the 2 design matrices [1pts]\n",
    "XModel1 = np.c_[FourierExpansion(FF.month/12, 6)]\n",
    "XModel1 = np.delete(XModel1, 10, axis=1)\n",
    "XModel2 = np.c_[pd.get_dummies(FF.month, drop_first=True)]\n",
    "\n",
    "# Build and evaluate the regression models [1pt: Model fitting, 1pt:R^2, 1pt: MSE]\n",
    "linreg1 = LinearRegression(fit_intercept=True) \n",
    "linreg1.fit(XModel1, FF.temp)\n",
    "yp = linreg1.predict(XModel1)\n",
    "mse1 = np.mean((FF.temp-yp)**2)\n",
    "r2_1 = linreg1.score(XModel1, FF.temp)\n",
    "\n",
    "linreg2 = LinearRegression(fit_intercept=True) \n",
    "linreg2.fit(XModel2,FF.temp)\n",
    "yp = linreg2.predict(XModel2)\n",
    "mse2 = np.mean((FF.temp-yp)**2)\n",
    "r2_2 = linreg2.score(XModel2,FF.temp)\n",
    "\n",
    "\n",
    "print(f'Mean Squared  error for Model 1: %.3f, %.3f' % (mse1, r2_1))\n",
    "print(f'Mean Squared  error for Model 2: %.3f, %.3f' % (mse2, r2_2))\n",
    "linreg2.rank_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Written answer: Both models fit the data equally well - they both have 11 regressors - so together with the intercept they can fit any arbitary non-linear function of month.** [1pt]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 3.4 (X / 12 pts)\n",
    "a) Modify your dummy encoding model (Model 2 from Question 3.3), by not dropping the first column. This design matrix should have 12 regressors now. \n",
    "\n",
    "b) Build a pipeline, which first applies z-Standardization to each column of the design matrix and then fit an L2-regularlized linear model. \n",
    "\n",
    "c) Do a grid search, varying the regularization parameter between $exp(-5)$ and $exp(4)$ in 30 steps for the fourier-encoded model, (Model 1 from Question 3.3). Evaluate each setting of $\\lambda$ using the mean-squared-error with 30-fold cross-validation. Plot the average validation error (y-axis) agains $log(\\lambda)$ (x-axis). (*Hint: If you did not succeed in generating a fourier feature set, use `polynomialFeatures` to make a polynomial feature set for month of order 11.*)\n",
    "\n",
    "d) Repeat c), this time using the dummy-coded feature set (modified Model 2 from question 3.4, part a). Plot the average validation error with a different color in the same plot as part c), so you can compare the models. \n",
    "\n",
    "e) Report the $\\lambda$ value for each model that gives the best validation error. \n",
    "\n",
    "Written answer: What do you see? Why don't the two models behave the same way, as they did Question 3.3? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# a. Generate new dummy encoding [1pt]\n",
    "XModel2 = np.c_[pd.get_dummies(FF.month,drop_first=False)]\n",
    "\n",
    "# b. Build the pipeline with StandardScaler and Ridge [1pt]\n",
    "pip = Pipeline([\n",
    "    ('std', StandardScaler()),\n",
    "    ('reg', Ridge())\n",
    "    ])\n",
    "\n",
    "# c. Grid search [5pts]\n",
    "log_lambda = np.linspace(-5,5,30)\n",
    "params = {'reg__alpha': np.exp(log_lambda)}\n",
    "gscv1 = GridSearchCV(pip, param_grid=params, cv=30, scoring = 'neg_mean_squared_error', refit=True)\n",
    "gscv1.fit(XModel1, FF.temp)\n",
    "MSE1 = -gscv1.cv_results_['mean_test_score']\n",
    "plt.scatter(log_lambda, MSE1,color='b')\n",
    "\n",
    "# d. \n",
    "gscv2 = GridSearchCV(pip, param_grid=params, cv=30, scoring = 'neg_mean_squared_error', refit=True)\n",
    "gscv2.fit(XModel2, FF.temp)\n",
    "MSE2 = -gscv2.cv_results_['mean_test_score']\n",
    "plt.scatter(log_lambda, MSE2,color='r')\n",
    "\n",
    "plt.xlabel(r'$-\\log(\\lambda)$')\n",
    "plt.ylabel('Validation error')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# e. Report the best regularization parameter [2pts]\n",
    "l1 = gscv1.best_params_['reg__alpha']\n",
    "l2 = gscv2.best_params_['reg__alpha']\n",
    "print(f'Model 1 lambda: %.3f' % l1)\n",
    "print(f'Model 2 lambda: %.3f' % l2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Written Answer: The two models behave differently - with the fourier set achieving lower validation error - and needing a lower value of the regularization parameter. While both regressor models span exactly the same linear space, regulatization pushes them towards different solution  - In the case of the fourier set / polynomial this will be a smoother function.** [2pts]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 3.5 (X / 8 pts)\n",
    "Now make a third model that has only a Fourier set of order 3 (or a polynomial feature set of order 5, if you did succeed in solving question 3.2). This is Model 3. \n",
    "Plot the same grid-search as in question 3.4 on this model and plot the validation error as a function of the regularization parameter. In the same plot, add the validation error for Model1 (Question 3.3/ 3.4). \n",
    "\n",
    "Written answer: \n",
    "You should see that Model 3 provides a better validation error for any setting of the ridge coefficient than the Model 1 considered in Question 3.4. Which one of the model is the more complex model? Which one is more likely to overfitting the data? Why can't L2-regularization fix this overfitting problem - why does the validation error for Model 1 not approach the validation error for Model 3?  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build the new model of order 3 [2pt]\n",
    "XModel3 = np.c_[FourierExpansion(FF.month/12,3)]\n",
    "\n",
    "# Get and plot the new test scores [2pts]\n",
    "gscv3 = GridSearchCV(pip, param_grid=params, cv=30, scoring = 'neg_mean_squared_error', refit=True)\n",
    "gscv3.fit(XModel3, FF.temp)\n",
    "MSE3 = -gscv3.cv_results_['mean_test_score']\n",
    "plt.scatter(log_lambda, MSE1,color='b')\n",
    "plt.scatter(log_lambda, MSE3,color='g')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Written answer: \n",
    "The Model 3 in 3.5 is less complex than the Model 1 in 3.4, as it has less regressors. Model 1 is therefore more prone to overfitting. [2pts]\n",
    "While regularization makes models \"less complex\", the ridge penality \"shrinks\" all regressor to the same degree. In this case the higher frequencies are as much impacted as the lower frequencies. Clearly, the temprature curve is smooth and high frequencies are not needed. To suppress the high frequencies in Model1 , the lower frequencies need to also be suppressed, increasing the bias of the model and leading to higher validation errors.** [2pt]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.6 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "vscode": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
