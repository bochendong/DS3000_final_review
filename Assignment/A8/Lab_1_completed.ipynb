{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "L0ukRfuauz6I"
   },
   "source": [
    "# Dimensionality Reduction\n",
    "\n",
    "In this lab, we will work with the IMDB to estimate the sentiment of movie reviews. We will study PCA and Sparse PCA in this context, and work using Single Value Decomposition to perform topic analysis. In the context of text mining, we call SVD *Latent Semantic Analysis* (LSA).\n",
    "\n",
    "LSA is already implemented in Python in scikit-learn in the package [*TruncatedSVD*](https://scikit-learn.org/stable/modules/generated/sklearn.decomposition.TruncatedSVD.html), we will use that along with the Natural Language Processing library [*NLTK*](https://www.nltk.org/) for our methods.\n",
    "\n",
    "The general process can be summarized as follows:\n",
    "\n",
    "1. Load the text in free form.\n",
    "2. Preprocess the text to normalize it.\n",
    "3. Calculate LSA.\n",
    "4. Explore the results."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eTsCGrpbuz6N"
   },
   "source": [
    "## Loading text: IMDB database.\n",
    "\n",
    "This dataset comes from the website Internet Movie Database, and represents 25,000 reviews which were labeled (by humans) as positive or negative, see [here](http://ai.stanford.edu/~amaas/data/sentiment/) for more details. It is a pretty big dataset, so we will work with small samples of 500 positive cases and 500 negative cases.\n",
    "\n",
    "The uncompressed data is simply a series of text documents, each in its own text file, stored in two classes, one per folder.\n",
    "\n",
    "The first step is to load the data and create a \"corpus\". A corpus is, quite simply, a set of documents. Here, we will read the files from our folders, and assign it a sentiment. We need to read the documents one by one, and store them into a dataset which will have our texts, and the tag considering whether they are positive or negative."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "COP_KBcSuz6N"
   },
   "source": [
    "### Reading the text\n",
    "\n",
    "The first step is to read the data into a vector. We need to read from the document path, using the internal system. This package is called *os* and comes pre-installed in Python.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.sparse import csr_matrix\n",
    "import sklearn.feature_extraction.text as sktext\n",
    "from sklearn.decomposition import PCA, SparsePCA, TruncatedSVD\n",
    "import re\n",
    "from sklearn.manifold import TSNE\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# UMAP: Uniform Manifold Approximation and Projection for Dimension Reduction\n",
    "# https://umap-learn.readthedocs.io/en/latest/\n",
    "# Import umap. Install first if not available!\n",
    "# !pip install umap-learn \n",
    "# !pip install datashader bokeh holoviews scikit-image colorcet ipywidgets\n",
    "import umap\n",
    "import umap.plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "vsU6UpZXvyVi",
    "outputId": "d0e4f7a3-dff5-4753-c35c-715be93e649a"
   },
   "outputs": [],
   "source": [
    "# Download the data\n",
    "# !gdown https://drive.google.com/uc?id=15AL-2F2Vdg9xlVmHfmeIOs3opnXoxzcP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "E6Rv_wR9v_R_",
    "outputId": "e0dc1fe1-f9c9-4a99-828a-6f340706744e"
   },
   "outputs": [],
   "source": [
    "# !unzip LSA_Sample.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['1_7.txt',\n",
       " '397_9.txt',\n",
       " '280_8.txt',\n",
       " '264_7.txt',\n",
       " '209_8.txt',\n",
       " '377_7.txt',\n",
       " '69_10.txt',\n",
       " '198_8.txt',\n",
       " '122_9.txt',\n",
       " '114_10.txt']"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# List all files in the positive samples. Replace with your own!\n",
    "dir = 'Lecture_Sample/train/pos/'\n",
    "fileList = os.listdir(dir)\n",
    "fileList[:10] # see first 10 files in the directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "mn54TuS5uz6O"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>texts</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>b\"If you like adult comedy cartoons, like Sout...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>b'I have to admit that Tsui Hark is one of a k...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>b\"Undying is a very good game which brings som...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>b\"Hickory Dickory Dock was a good Poirot myste...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>b\"Walter Matthau and George Burns just work so...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               texts  class\n",
       "0  b\"If you like adult comedy cartoons, like Sout...      1\n",
       "1  b'I have to admit that Tsui Hark is one of a k...      1\n",
       "2  b\"Undying is a very good game which brings som...      1\n",
       "3  b\"Hickory Dickory Dock was a good Poirot myste...      1\n",
       "4  b\"Walter Matthau and George Burns just work so...      1"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create vector with texts\n",
    "outtexts = []\n",
    "\n",
    "# Read the files in the directory and append them with the class to the dataset\n",
    "for eachFile in fileList:\n",
    "    with open(dir + eachFile, 'rb', newline = None) as _fp:\n",
    "        fileData = _fp.read()\n",
    "        outtexts.append(fileData)\n",
    "    _fp.close()\n",
    "    \n",
    "# Create dataframe from outputs\n",
    "texts = pd.DataFrame({'texts': outtexts, 'class': 1})\n",
    "texts.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "PYyiR9Y0uz6Q"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>texts</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>995</th>\n",
       "      <td>b'You may consider a couple of facts in the di...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>996</th>\n",
       "      <td>b'What is this crap? My little cousin picked t...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997</th>\n",
       "      <td>b\"This film was choppy, incoherent and contriv...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>998</th>\n",
       "      <td>b\"This film, once sensational for its forward-...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999</th>\n",
       "      <td>b'It as absolutely incredible to me that anyon...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 texts  class\n",
       "995  b'You may consider a couple of facts in the di...      0\n",
       "996  b'What is this crap? My little cousin picked t...      0\n",
       "997  b\"This film was choppy, incoherent and contriv...      0\n",
       "998  b\"This film, once sensational for its forward-...      0\n",
       "999  b'It as absolutely incredible to me that anyon...      0"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Repeat for negative values\n",
    "# List all files in the \"pos\" directory\n",
    "dir = 'Lecture_Sample/train/neg/'\n",
    "fileList = os.listdir(dir)\n",
    "\n",
    "# Create vector with texts\n",
    "outtexts = []\n",
    "\n",
    "# Read the files in the directory and append them with the class to the dataset\n",
    "for eachFile in fileList:\n",
    "    with open(dir + eachFile, 'rb', newline = None) as _fp:\n",
    "        fileData = _fp.read()\n",
    "        outtexts.append(fileData)\n",
    "    _fp.close()\n",
    "    \n",
    "# Create dataframe from outputs\n",
    "texts = pd.concat((texts, pd.DataFrame({'texts': outtexts, 'class': 0})), ignore_index = True)\n",
    "texts.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 300
    },
    "id": "NsBTAHRMuz6Q",
    "outputId": "4db8e825-fbe7-49e3-e7a4-feacbcbdfbba"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1000.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.50000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.50025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.50000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.00000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            class\n",
       "count  1000.00000\n",
       "mean      0.50000\n",
       "std       0.50025\n",
       "min       0.00000\n",
       "25%       0.00000\n",
       "50%       0.50000\n",
       "75%       1.00000\n",
       "max       1.00000"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "texts.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 424
    },
    "id": "zMKZins2wN_P",
    "outputId": "7202bed7-4dc4-40f8-9e07-b5ab7603b50d"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>texts</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>b\"If you like adult comedy cartoons, like Sout...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>b'I have to admit that Tsui Hark is one of a k...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>b\"Undying is a very good game which brings som...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>b\"Hickory Dickory Dock was a good Poirot myste...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>b\"Walter Matthau and George Burns just work so...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>995</th>\n",
       "      <td>b'You may consider a couple of facts in the di...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>996</th>\n",
       "      <td>b'What is this crap? My little cousin picked t...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997</th>\n",
       "      <td>b\"This film was choppy, incoherent and contriv...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>998</th>\n",
       "      <td>b\"This film, once sensational for its forward-...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999</th>\n",
       "      <td>b'It as absolutely incredible to me that anyon...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1000 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 texts  class\n",
       "0    b\"If you like adult comedy cartoons, like Sout...      1\n",
       "1    b'I have to admit that Tsui Hark is one of a k...      1\n",
       "2    b\"Undying is a very good game which brings som...      1\n",
       "3    b\"Hickory Dickory Dock was a good Poirot myste...      1\n",
       "4    b\"Walter Matthau and George Burns just work so...      1\n",
       "..                                                 ...    ...\n",
       "995  b'You may consider a couple of facts in the di...      0\n",
       "996  b'What is this crap? My little cousin picked t...      0\n",
       "997  b\"This film was choppy, incoherent and contriv...      0\n",
       "998  b\"This film, once sensational for its forward-...      0\n",
       "999  b'It as absolutely incredible to me that anyon...      0\n",
       "\n",
       "[1000 rows x 2 columns]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "texts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The text is quite dirty, so we'll use regex code to clean it. It is available in Python using the package [re](https://www.rexegg.com/regex-quickstart.html). Regex can be daunting, but it is very rewarding to learn. Do spend some time with it!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>texts</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>If you like adult comedy cartoons, like South ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>I have to admit that Tsui Hark is one of a kin...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Undying is a very good game which brings some ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Hickory Dickory Dock was a good Poirot mystery...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Walter Matthau and George Burns just work so w...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>995</th>\n",
       "      <td>You may consider a couple of facts in the disc...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>996</th>\n",
       "      <td>What is this crap? My little cousin picked thi...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997</th>\n",
       "      <td>This film was choppy, incoherent and contrived...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>998</th>\n",
       "      <td>This film, once sensational for its forward-th...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999</th>\n",
       "      <td>It as absolutely incredible to me that anyone ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1000 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 texts  class\n",
       "0    If you like adult comedy cartoons, like South ...      1\n",
       "1    I have to admit that Tsui Hark is one of a kin...      1\n",
       "2    Undying is a very good game which brings some ...      1\n",
       "3    Hickory Dickory Dock was a good Poirot mystery...      1\n",
       "4    Walter Matthau and George Burns just work so w...      1\n",
       "..                                                 ...    ...\n",
       "995  You may consider a couple of facts in the disc...      0\n",
       "996  What is this crap? My little cousin picked thi...      0\n",
       "997  This film was choppy, incoherent and contrived...      0\n",
       "998  This film, once sensational for its forward-th...      0\n",
       "999  It as absolutely incredible to me that anyone ...      0\n",
       "\n",
       "[1000 rows x 2 columns]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "CLEANR = re.compile('<.*?>|&([a-z0-9]+|#[0-9]{1,6}|#x[0-9a-f]{1,6});')\n",
    "def cleanhtml(raw_html):\n",
    "    html = raw_html.decode('ISO-8859-1') # Change the encoding to your locale!\n",
    "    cleantext = re.sub(CLEANR, '', html)\n",
    "    return cleantext\n",
    "\n",
    "texts['texts'] = texts['texts'].apply(cleanhtml)\n",
    "texts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we will transform the text. The following code uses sklearn's [TfidfVectorizer](https://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.TfidfVectorizer.html) which applies a [Term Frequency - Inverse Document Frequency](https://en.wikipedia.org/wiki/Tf%E2%80%93idf) transformation to the text, which means counting how many times a certain concept appears in the document versus the total times it appears in the document, to do the following:\n",
    "\n",
    "1. Eliminate accents and other characters.\n",
    "2. Eliminate the so-called \"stopwords\", or words that are irrelevant to the learning given they are only connectors. These words are [here](https://gist.github.com/ethen8181/d57e762f81aa643744c2ffba5688d33a).\n",
    "3. Eliminate concepts that are rare (min_df) or too common (max_df). Here we eliminate concepts that appear in less than 5% of documents and those that appear in over 90%.\n",
    "\n",
    "The last argument calculates a logaritmic (or sublinear) transformation, which is more robust. This effectively transforms our dataset into a fully numeric one!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "id": "lT9LAUx0uz6R"
   },
   "outputs": [],
   "source": [
    "# Transform the text\n",
    "TfIDFTransformer = sktext.TfidfVectorizer(strip_accents='unicode', # Eliminate accents and special characters\n",
    "                      stop_words='english', # Eliminates stop words.\n",
    "                      min_df = 0.05, # Eliminate words that do not appear in more than 5% of texts\n",
    "                      max_df = 0.90, # Eliminate words that appear in more than 95% of texts\n",
    "                      sublinear_tf=True # Use sublinear weights (softplus)\n",
    "                      )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JwCWLFfBuz6R"
   },
   "source": [
    "The model structure of scikit-learn follows always the same:\n",
    "\n",
    "1. We define the model using the appropriate function directly from the package (as above).\n",
    "\n",
    "2. We train the model using the \"fit\" method over the object we created in 1.\n",
    "\n",
    "3. We apply the model to new data using the \"transform\" method.\n",
    "\n",
    "In cases where we want to fit *and* transform the inputs - such as a TF-IDF transform, which is applied over the same data where the weights are \"trained\" - we can use directly the method \"fit_transform\", that performs steps 2 and 3 directly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "id": "Vq6XbDpMuz6S",
    "outputId": "3b8fb1fc-4c6f-43b0-b31d-25712ad7a8cd"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<1000x230 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 23848 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TfIDF_IMDB = TfIDFTransformer.fit_transform(texts['texts'])\n",
    "TfIDF_IMDB"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Rkh6lVSouz6S"
   },
   "source": [
    "The output is a **sparse matrix** with 1647 words. These matrices only store the relevant information! They are *much* more efficient in-memory.\n",
    "\n",
    "The output of the TF-IDF transformer is a sparse matrix. We can check the outputs of the first row with the below code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "id": "wnj4CNPBuz6S",
    "outputId": "5bbbd3bc-efab-4a02-88c6-d551d89bc40e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (0, 25)\t0.26221561360196516\n",
      "  (0, 102)\t0.19553930525319846\n",
      "  (0, 43)\t0.20636328414550276\n",
      "  (0, 27)\t0.20986235766373093\n",
      "  (0, 167)\t0.2666753264211833\n",
      "  (0, 79)\t0.21743149588993194\n",
      "  (0, 80)\t0.2936185733749881\n",
      "  (0, 195)\t0.18088119475091288\n",
      "  (0, 76)\t0.2666753264211833\n",
      "  (0, 87)\t0.25904739767431134\n",
      "  (0, 75)\t0.27268042611426274\n",
      "  (0, 180)\t0.47280717413125994\n",
      "  (0, 33)\t0.24255769565192892\n",
      "  (0, 107)\t0.27221410897561893\n"
     ]
    }
   ],
   "source": [
    "print(TfIDF_IMDB[0,:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lB06CGntuz6T"
   },
   "source": [
    " The following vector shows the list of words associated to each index for indexes 30 to 39."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "id": "HDAXoohsuz6T",
    "outputId": "c364e63b-1195-4d84-ca91-8097e6df0960"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['cinema' 'classic' 'come' 'comedy' 'comes' 'completely' 'couldn' 'couple'\n",
      " 'course' 'day']\n"
     ]
    }
   ],
   "source": [
    "print(TfIDFTransformer.get_feature_names_out()[30:40])\n",
    "\n",
    "# Let's save the indexes for later.\n",
    "word_index = TfIDFTransformer.get_feature_names_out ()"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "Lab 7 - LSA.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3.10.6 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "vscode": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
