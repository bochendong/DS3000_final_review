{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt \n",
    "import seaborn as sns\n",
    "\n",
    "import scipy.optimize as so\n",
    "from scipy.optimize import minimize\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, KFold\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_absolute_percentage_error # Requires sklearn 0.24 (December 2020), update with conda/pip if needed.\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV, train_test_split, StratifiedKFold\n",
    "\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.metrics import roc_curve, precision_recall_curve, auc\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.metrics import make_scorer\n",
    "seed = 42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cal_r2(y, ypred):\n",
    "    RSS = np.sum((y - ypred) ** 2)\n",
    "    TSS = sum((y - np.mean(y))**2)\n",
    "    return 1 - RSS/TSS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Class Balanced"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('diabetes.csv')\n",
    "counts= df.Outcome.value_counts()\n",
    "\n",
    "baseline_accuracy = round(counts[0]/(counts[0]+counts[1]), 3)\n",
    "print(\"Baseline Accuracy is:\", baseline_accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bootstrap and confidence interval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_csv('hockey_draftees_2005.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bootstrap on parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write a Bootstrap function that records the fitted models \n",
    "def BootstrapCoef(data, numboot):\n",
    "    # Write the function here\n",
    "    n = len(data)\n",
    "    theta = np.zeros((numboot,3))\n",
    "    for i in range(numboot):\n",
    "        new_df =  data.sample(n, replace=True)\n",
    "\n",
    "        x = new_df['wt']\n",
    "        X = np.c_[x, x**2]\n",
    "        y = new_df['overall']\n",
    "\n",
    "        reg = LinearRegression().fit(X, y)\n",
    "        intercept = reg.intercept_\n",
    "        coef = reg.coef_\n",
    "        theta[i][0] = intercept\n",
    "        theta[i][1] = coef[0]\n",
    "        theta[i][2] = coef[1]\n",
    "\n",
    "    return theta\n",
    "\n",
    "params = BootstrapCoef(df,100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = sns.jointplot(x=params[:,0],y=params[:,2])\n",
    "ax.ax_joint.set_xlabel('Intercept')\n",
    "ax.ax_joint.set_ylabel('Quadratic')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Boostrap on fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write a Bootstrap function that records the fitted models \n",
    "def BootstrapPred(data,xp):\n",
    "    numboot = 20\n",
    "    n = len(data)\n",
    "    \n",
    "    X_pred = np.c_[xp, xp**2]\n",
    "    y_pred = np.zeros((numboot,X_pred.shape[0]))   \n",
    "    for i in range(numboot):\n",
    "        new_df =  data.sample(len(data), replace=True)\n",
    "        x = new_df['wt']\n",
    "        X = np.c_[x, x**2]\n",
    "        y = new_df['overall']\n",
    "        reg = LinearRegression().fit(X, y)\n",
    "\n",
    "        y_pred[i,:] = reg.predict(X_pred)\n",
    "\n",
    "    return y_pred\n",
    "\n",
    "\n",
    "# Get predictions from 20 bootstrapped models \n",
    "x_grid = np.linspace(170, 250, 100)\n",
    "y_pred = BootstrapPred(df, x_grid)\n",
    "\n",
    "# Make a scatterplot and draw the 20 lines  \n",
    "for i in range(20):\n",
    "    plt.plot(x_grid, y_pred[i,:])\n",
    "plt.scatter(df['wt'], df['overall'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Confidence interval (Noral Distribution)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate bootstrap interval\n",
    "boot_ci = [np.quantile(params[:,2], 0.025, axis=0) ,\n",
    "        np.quantile(params[:,2], 0.975, axis=0)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Confidence interval (t-distribution)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "t-distribution , which is more accurate for small sample sizes.  \n",
    "\n",
    "The $100(1-\\alpha)\\%$ confidence interval is \n",
    "\n",
    "\n",
    "$$ \\bar{x} \\pm  t_{1-\\alpha/2, n-1} \\dfrac{\\hat{\\sigma}}{\\sqrt{n}} $$\n",
    "\n",
    "Where $ t_{1-\\alpha/2, n-1}$ is the appropiorate quantile of a Student's t distribution with $n-1$ degrees of freedom.  \n",
    "Write a function called `confidence_interval` which takes as it's argument an array of data called `data` and returns two things:\n",
    "\n",
    "* An estimated mean of `data`, and \n",
    "\n",
    "* The lower and upper bounds of the 95% confidence interval for the mean of `data`.  Ensure these are returned in a numpy array of shape (2,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import t\n",
    "def confidence_interval(data):\n",
    "    # Note, np.std divides by n and not n-1\n",
    "    # Force it to apply the correct formula by ussing ddof=1\n",
    "    # Alternatively, you can use scipy.stats.sem to compute\n",
    "    # The standard error\n",
    "    mean = np.mean(data)\n",
    "    std = np.std(data, ddof = 1)\n",
    "    confidence = 0.95\n",
    "    t_crit = np.abs(t.ppf((1-confidence)/2, len(data) - 1))\n",
    "    bounds = (mean - std * t_crit / np.sqrt(len(data)), \n",
    "                mean + std *t_crit / np.sqrt(len(data))) \n",
    "    \n",
    "    return mean, bounds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Confidence interval (Central limit theorem)\n",
    "\n",
    "Compute (and print) a 95% confidence interval for the average test error using the Central Limit Theorem. You can use the following formula to compute it: \n",
    "\n",
    "$$ \\bar{L_n} \\pm 1.96 * \\frac{\\sigma_{l}}{\\sqrt{n}}$$\n",
    "\n",
    "Here $\\bar{L_n}$ is the average test loss (i.e. for our test set), $\\sigma_l$ is the standard deviation (of our test losses), and $n$ is the total number of test losses we compute. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def confidence_interval(ypred, ytest):\n",
    "    loss = ypred - ytest\n",
    "\n",
    "    lossMean = np.mean((ypred - ytest)**2)\n",
    "\n",
    "    # Calculate the 95% Confidence Interval for average test loss\n",
    "\n",
    "    stdErr = np.std(loss, ddof=1)/np.sqrt(len(loss))\n",
    "\n",
    "    ci = [lossMean - 1.96 * stdErr, lossMean + 1.96 * stdErr]\n",
    "\n",
    "    print('Confidence Interval is:', ci)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Statistical Significance "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('forestfires.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "aug    35.59\n",
       "sep    33.27\n",
       "mar    10.44\n",
       "jul     6.19\n",
       "feb     3.87\n",
       "jun     3.29\n",
       "oct     2.90\n",
       "apr     1.74\n",
       "dec     1.74\n",
       "jan     0.39\n",
       "may     0.39\n",
       "nov     0.19\n",
       "Name: month, dtype: float64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "((df.month.value_counts()/df.month.value_counts().sum())*100).round(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Group insignificant labels into two new statistically significant labels.\n",
    "df.month.replace({'feb':'fj', 'jun':'fj'}, inplace=True)\n",
    "\n",
    "df.month.replace({'oct':'oadjmn', 'apr':'oadjmn', 'dec':'oadjmn', \n",
    "    'jan':'oadjmn', 'may':'oadjmn', \n",
    "    'nov':'oadjmn'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "aug       35.59\n",
       "sep       33.27\n",
       "mar       10.44\n",
       "oadjmn     7.35\n",
       "fj         7.16\n",
       "jul        6.19\n",
       "Name: month, dtype: float64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "((df.month.value_counts()/df.month.value_counts().sum())*100).round(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Convert\n",
    "convert all categorical data into numerical data using `get_dummies`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.get_dummies(df, drop_first=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "M1 = Pipeline([\n",
    "    ('lr1', LinearRegression())\n",
    "])\n",
    "\n",
    "M2 = Pipeline([\n",
    "    ('poly', PolynomialFeatures(degree=2, include_bias=False)),\n",
    "    ('lr3', LinearRegression())\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Custom Transformer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`Temperature (temp)` and `Rain (rain)` may be important features, so let's extend model 1 by adding a *cubed* term for temp and a *squared* term for rain."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class KeyFeatures(BaseEstimator, TransformerMixin):\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "\n",
    "    def transform(self, X, y=None):\n",
    "        X = X.assign(temp2 = X.temp**3)\n",
    "        X = X.assign(rain2 = X.rain**2)\n",
    "        return X\n",
    "\n",
    "# Create a pipeline for model 3 (M3) [ /8 marks]\n",
    "M3 = Pipeline([\n",
    "    ('temp_cubic_rain_square', KeyFeatures()),\n",
    "    ('lr2', LinearRegression())\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# K-flod cross-validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def MSE(y, ypr):\n",
    "    return np.mean((y-ypr)**2)\n",
    "    \n",
    "kf = KFold(n_splits=4)\n",
    "sc = make_scorer(MSE) \n",
    "\n",
    "cvsc1 = cross_val_score(M1, Xtrain, ytrain, cv=kf, scoring=sc)\n",
    "cvsc2 = cross_val_score(M2, Xtrain, ytrain, cv=kf, scoring=sc)\n",
    "cvsc3 = cross_val_score(M3, Xtrain, ytrain, cv=kf, scoring=sc)\n",
    "\n",
    "print(f\"M1 loss: %.4f +/- %.4f\" % (cvsc1.mean(), cvsc1.std()))\n",
    "print(f\"M2 loss: %.4f +/- %.4f\" % (cvsc2.mean(), cvsc2.std()))\n",
    "print(f\"M3 loss: %.4f +/- %.4f\" % (cvsc3.mean(), cvsc3.std()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Trees"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('energy_appliances_standard.csv')\n",
    "y = df[\"Appliances\"]\n",
    "X =  df.drop(\"Appliances\",axis=1)\n",
    "RANDOM_STATE = 20201107\n",
    "Xtrain, Xtest, ytrain, ytest = train_test_split(X,y, test_size = 0.3, random_state = seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ff = RandomForestRegressor(\n",
    "            n_estimators = 250,\n",
    "            max_features=None,\n",
    "            oob_score=True,\n",
    "            random_state=RANDOM_STATE,\n",
    "        )\n",
    "\n",
    "ff.fit(Xtrain, ytrain)\n",
    "\n",
    "# Calculate error over test set\n",
    "y_pred = ff.predict(Xtest)\n",
    "err_test = mean_absolute_percentage_error(y_pred, ytest)\n",
    "\n",
    "print(\"MAPE (test set): %f\" % err_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## XGboosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('energy_appliances_standard.csv')\n",
    "y = df[\"Appliances\"]\n",
    "X =  df.drop(\"Appliances\",axis=1)\n",
    "Xtrain, Xtest, ytrain, ytest = train_test_split(X,y, test_size = 0.3, random_state = RANDOM_STATE)\n",
    "\n",
    "XGB_opt = XGBRegressor(learning_rate = 0.1,  \n",
    "                            max_depth =  7,\n",
    "                            n_estimators = 450,\n",
    "                            verbosity=1,                  # If to show more errors or not.\n",
    "                            objective='reg:squarederror',       # Type of target variable.\n",
    "                            booster='gbtree',             # What to boost. Trees in this case.\n",
    "                            n_jobs=-1,                    # Parallel jobs to run. Set your processor number.\n",
    "                            gamma=0.001,                  # Minimum loss reduction required to make a further partition on a leaf node of the tree. (Controls growth!)\n",
    "                            subsample=0.632,              # Subsample ratio. Can set lower\n",
    "                            colsample_bytree=1,           # Subsample ratio of columns when constructing each tree.\n",
    "                            colsample_bylevel=1,          # Subsample ratio of columns when constructing each level. 0.33 is similar to random forest.\n",
    "                            colsample_bynode=1,           # Subsample ratio of columns when constructing each split.\n",
    "                            base_score=0.5,               # Global bias. Set to average of the target rate.\n",
    "                            random_state=RANDOM_STATE        # Seed\n",
    "                            )\n",
    "\n",
    "\n",
    "XGB_opt.fit(Xtrain, ytrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_xgb = XGB_opt.predict(Xtest)\n",
    "err_test_xgb = mean_absolute_percentage_error(y_pred_xgb, ytest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Variable importance\n",
    "importances = XGB_opt.feature_importances_\n",
    "indices = np.argsort(importances)[::-1] \n",
    "\n",
    "f, ax = plt.subplots(figsize=(3, 8))\n",
    "plt.title(\"Variable Importance - XGBoosting\")\n",
    "sns.set_color_codes(\"pastel\")\n",
    "sns.barplot(y=[Xtrain.columns[i] for i in indices], x=importances[indices], \n",
    "            label=\"Total\", color=\"b\")\n",
    "ax.set(ylabel=\"Variable\",\n",
    "       xlabel=\"Variable Importance\")\n",
    "sns.despine(left=True, bottom=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dimension Reduction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import umap.umap_ as umap\n",
    "from sklearn.decomposition import PCA, TruncatedSVD\n",
    "from sklearn.linear_model import LogisticRegressionCV"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import silhouette_samples, silhouette_score"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.6 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
